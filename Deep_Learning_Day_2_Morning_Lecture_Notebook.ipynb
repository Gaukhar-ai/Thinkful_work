{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Day 2 Morning Lecture Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaukhar-ai/Thinkful_work/blob/master/Deep_Learning_Day_2_Morning_Lecture_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VINmTMTrrA3e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0hX2etAuMwQ"
      },
      "source": [
        "def relu(x):\n",
        "  if x > 0:\n",
        "    return x\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc4H15rbuVo5"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54-IgWDyuetp",
        "outputId": "c9238295-a7ab-4103-a4ff-678906cc036b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "x = np.linspace(-5,5,101)\n",
        "y = [relu(z) for z in x]\n",
        "\n",
        "df = pd.DataFrame({'x':x, 'y': y})\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.8</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-4.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>4.6</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>4.7</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>4.8</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>4.9</td>\n",
              "      <td>4.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       x    y\n",
              "0   -5.0  0.0\n",
              "1   -4.9  0.0\n",
              "2   -4.8  0.0\n",
              "3   -4.7  0.0\n",
              "4   -4.6  0.0\n",
              "..   ...  ...\n",
              "96   4.6  4.6\n",
              "97   4.7  4.7\n",
              "98   4.8  4.8\n",
              "99   4.9  4.9\n",
              "100  5.0  5.0\n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzeIQ8d9umRc",
        "outputId": "ffc8deda-dc3e-4f58-ea02-f62ab2d926a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "df.plot(x='x', y='y')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7be4d73f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao8DJk5Ou_-D",
        "outputId": "f0e45f1f-7cbf-4a5c-f2e7-cc7f40d631ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "x = np.linspace(-5,5,101)\n",
        "y = [sigmoid(z) for z in x]\n",
        "\n",
        "df = pd.DataFrame({'x':x, 'y': y})\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.006693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.9</td>\n",
              "      <td>0.007392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.8</td>\n",
              "      <td>0.008163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-4.7</td>\n",
              "      <td>0.009013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.6</td>\n",
              "      <td>0.009952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>4.6</td>\n",
              "      <td>0.990048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>4.7</td>\n",
              "      <td>0.990987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>4.8</td>\n",
              "      <td>0.991837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>4.9</td>\n",
              "      <td>0.992608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.993307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       x         y\n",
              "0   -5.0  0.006693\n",
              "1   -4.9  0.007392\n",
              "2   -4.8  0.008163\n",
              "3   -4.7  0.009013\n",
              "4   -4.6  0.009952\n",
              "..   ...       ...\n",
              "96   4.6  0.990048\n",
              "97   4.7  0.990987\n",
              "98   4.8  0.991837\n",
              "99   4.9  0.992608\n",
              "100  5.0  0.993307\n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2T6Yg3YvPc5",
        "outputId": "4b1c796c-3111-49b7-fc2c-c9864fc779ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "df.plot(x='x', y='y')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7be4d1de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwTRvEDnvWeS"
      },
      "source": [
        "def leaky_relu(x):\n",
        "  if x > 0:\n",
        "    return x\n",
        "  else:\n",
        "    return 0.01 * x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDuCyoHfwKFo",
        "outputId": "b6b85ae1-c5bc-4f5d-cb4f-8fe43c582178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "x = np.linspace(-5,5,101)\n",
        "y = [leaky_relu(z) for z in x]\n",
        "\n",
        "df = pd.DataFrame({'x':x, 'y': y})\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>-0.050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.9</td>\n",
              "      <td>-0.049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.8</td>\n",
              "      <td>-0.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-4.7</td>\n",
              "      <td>-0.047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>4.6</td>\n",
              "      <td>4.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>4.7</td>\n",
              "      <td>4.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>4.8</td>\n",
              "      <td>4.800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>4.9</td>\n",
              "      <td>4.900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       x      y\n",
              "0   -5.0 -0.050\n",
              "1   -4.9 -0.049\n",
              "2   -4.8 -0.048\n",
              "3   -4.7 -0.047\n",
              "4   -4.6 -0.046\n",
              "..   ...    ...\n",
              "96   4.6  4.600\n",
              "97   4.7  4.700\n",
              "98   4.8  4.800\n",
              "99   4.9  4.900\n",
              "100  5.0  5.000\n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aro1zPNwNNI",
        "outputId": "044a22a9-5230-4165-f1d7-62986d5d0560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "df.plot(x='x', y='y')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7be48077f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4B6nubGwRNP"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Age -  ranges from 18 to 40  \n",
        "# Delivery number - ranges from 1 to 4\n",
        "# Delivery time -  {0 = timely , 1 = premature , 2 = latecomer}\n",
        "# Blood of Pressure - {0 = low , 1 = normal , 2 = high }\n",
        "# Heart Problem - {0 = apt, 1 = inept }\n",
        "# Target - Caesarian - {0 = No, 1 = Yes }\n",
        "\n",
        "csection = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/csection.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2elOfIeUw3tL",
        "outputId": "077cc0d3-3136-494b-ce7e-f471fee28607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "csection.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Delivery number</th>\n",
              "      <th>Delivery time</th>\n",
              "      <th>Blood Pressure</th>\n",
              "      <th>Heart Problem</th>\n",
              "      <th>Caesarian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Delivery number  ...  Heart Problem  Caesarian\n",
              "0   22                1  ...              0          0\n",
              "1   26                2  ...              0          1\n",
              "2   26                2  ...              0          0\n",
              "3   28                1  ...              0          0\n",
              "4   22                2  ...              0          1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ly48eXlw3vU",
        "outputId": "9f8407f6-34f4-4105-9c90-933b60f04caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "csection.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 80 entries, 0 to 79\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype\n",
            "---  ------           --------------  -----\n",
            " 0   Age              80 non-null     int64\n",
            " 1   Delivery number  80 non-null     int64\n",
            " 2   Delivery time    80 non-null     int64\n",
            " 3   Blood Pressure   80 non-null     int64\n",
            " 4   Heart Problem    80 non-null     int64\n",
            " 5   Caesarian        80 non-null     int64\n",
            "dtypes: int64(6)\n",
            "memory usage: 3.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faa_zsRCw3xa"
      },
      "source": [
        "c_dummy = pd.get_dummies(csection, columns=['Delivery number', 'Delivery time', 'Heart Problem'], drop_first=True)\n",
        "\n",
        "x = c_dummy.drop(columns=['Caesarian'])\n",
        "y = c_dummy['Caesarian']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UHsgXsw3zk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1pkJdwow311"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwtaFND-y2hI",
        "outputId": "6fc8cf02-7b3b-44f7-e1f3-0eeac2b39dd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape[1]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DXxnJcxw33-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='tanh'))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxL6kEjOw36Y"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEq0_MDzhsw",
        "outputId": "670e9dcf-598a-4810-c1cb-304b9d34ceb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 833\n",
            "Trainable params: 833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQfCvt_jzkT5",
        "outputId": "c4dccbf6-707b-46d0-e18a-f0a0f7619388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=50)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.5167 - accuracy: 0.5625 - val_loss: 0.9206 - val_accuracy: 0.6250\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9476 - accuracy: 0.5625 - val_loss: 1.0707 - val_accuracy: 0.2500\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1289 - accuracy: 0.4688 - val_loss: 2.2256 - val_accuracy: 0.2500\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4718 - accuracy: 0.4688 - val_loss: 0.8869 - val_accuracy: 0.3750\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8314 - accuracy: 0.4375 - val_loss: 0.8607 - val_accuracy: 0.6250\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9524 - accuracy: 0.5625 - val_loss: 0.9369 - val_accuracy: 0.6250\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0644 - accuracy: 0.5625 - val_loss: 0.9886 - val_accuracy: 0.6250\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1332 - accuracy: 0.5625 - val_loss: 1.0014 - val_accuracy: 0.6250\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1446 - accuracy: 0.5625 - val_loss: 0.9756 - val_accuracy: 0.6250\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1036 - accuracy: 0.5625 - val_loss: 0.9212 - val_accuracy: 0.6250\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0210 - accuracy: 0.5625 - val_loss: 0.8659 - val_accuracy: 0.6250\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9174 - accuracy: 0.5469 - val_loss: 0.8345 - val_accuracy: 0.6250\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8436 - accuracy: 0.5469 - val_loss: 0.8679 - val_accuracy: 0.4375\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8107 - accuracy: 0.4219 - val_loss: 0.9915 - val_accuracy: 0.2500\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8625 - accuracy: 0.4844 - val_loss: 1.0733 - val_accuracy: 0.2500\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8897 - accuracy: 0.4844 - val_loss: 0.9590 - val_accuracy: 0.2500\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8177 - accuracy: 0.5000 - val_loss: 0.8631 - val_accuracy: 0.4375\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8125 - accuracy: 0.4375 - val_loss: 0.8281 - val_accuracy: 0.5000\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8140 - accuracy: 0.5469 - val_loss: 0.8227 - val_accuracy: 0.6250\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8227 - accuracy: 0.5781 - val_loss: 0.8207 - val_accuracy: 0.6250\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8177 - accuracy: 0.5625 - val_loss: 0.8209 - val_accuracy: 0.5000\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8023 - accuracy: 0.5312 - val_loss: 0.8312 - val_accuracy: 0.3750\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7867 - accuracy: 0.4688 - val_loss: 0.8600 - val_accuracy: 0.4375\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7830 - accuracy: 0.5000 - val_loss: 0.9073 - val_accuracy: 0.2500\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7978 - accuracy: 0.4844 - val_loss: 0.9518 - val_accuracy: 0.2500\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8192 - accuracy: 0.4844 - val_loss: 0.9330 - val_accuracy: 0.2500\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8102 - accuracy: 0.4688 - val_loss: 0.8713 - val_accuracy: 0.3125\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7802 - accuracy: 0.4844 - val_loss: 0.8337 - val_accuracy: 0.4375\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7716 - accuracy: 0.4531 - val_loss: 0.8112 - val_accuracy: 0.3750\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7745 - accuracy: 0.5312 - val_loss: 0.8014 - val_accuracy: 0.5625\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7870 - accuracy: 0.5312 - val_loss: 0.7983 - val_accuracy: 0.6250\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7925 - accuracy: 0.5312 - val_loss: 0.7971 - val_accuracy: 0.6250\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7862 - accuracy: 0.5312 - val_loss: 0.7999 - val_accuracy: 0.5000\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7703 - accuracy: 0.5469 - val_loss: 0.8129 - val_accuracy: 0.4375\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7666 - accuracy: 0.4531 - val_loss: 0.8387 - val_accuracy: 0.4375\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7642 - accuracy: 0.5000 - val_loss: 0.8540 - val_accuracy: 0.3125\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7673 - accuracy: 0.5000 - val_loss: 0.8490 - val_accuracy: 0.3125\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7632 - accuracy: 0.5000 - val_loss: 0.8275 - val_accuracy: 0.4375\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7583 - accuracy: 0.5000 - val_loss: 0.8079 - val_accuracy: 0.4375\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7544 - accuracy: 0.4688 - val_loss: 0.7959 - val_accuracy: 0.3750\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7563 - accuracy: 0.5625 - val_loss: 0.7880 - val_accuracy: 0.5000\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7687 - accuracy: 0.5312 - val_loss: 0.7859 - val_accuracy: 0.5625\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7648 - accuracy: 0.5312 - val_loss: 0.7892 - val_accuracy: 0.5000\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7520 - accuracy: 0.5781 - val_loss: 0.8038 - val_accuracy: 0.4375\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7513 - accuracy: 0.4844 - val_loss: 0.8349 - val_accuracy: 0.4375\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7521 - accuracy: 0.5000 - val_loss: 0.8476 - val_accuracy: 0.3125\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7557 - accuracy: 0.5469 - val_loss: 0.8427 - val_accuracy: 0.3750\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7523 - accuracy: 0.5625 - val_loss: 0.8270 - val_accuracy: 0.4375\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7439 - accuracy: 0.5000 - val_loss: 0.7984 - val_accuracy: 0.4375\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7421 - accuracy: 0.5000 - val_loss: 0.7823 - val_accuracy: 0.4375\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7437 - accuracy: 0.5625 - val_loss: 0.7788 - val_accuracy: 0.5000\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7458 - accuracy: 0.5781 - val_loss: 0.7781 - val_accuracy: 0.5000\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7428 - accuracy: 0.5781 - val_loss: 0.7771 - val_accuracy: 0.5000\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7375 - accuracy: 0.5938 - val_loss: 0.7867 - val_accuracy: 0.3750\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7446 - accuracy: 0.5312 - val_loss: 0.7996 - val_accuracy: 0.4375\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7323 - accuracy: 0.5000 - val_loss: 0.7917 - val_accuracy: 0.4375\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7302 - accuracy: 0.5156 - val_loss: 0.7824 - val_accuracy: 0.3750\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7313 - accuracy: 0.5781 - val_loss: 0.7764 - val_accuracy: 0.4375\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7299 - accuracy: 0.5781 - val_loss: 0.7767 - val_accuracy: 0.4375\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7279 - accuracy: 0.5781 - val_loss: 0.7807 - val_accuracy: 0.3750\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7252 - accuracy: 0.5469 - val_loss: 0.7921 - val_accuracy: 0.4375\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7262 - accuracy: 0.5156 - val_loss: 0.8030 - val_accuracy: 0.4375\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7274 - accuracy: 0.5469 - val_loss: 0.7989 - val_accuracy: 0.4375\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7287 - accuracy: 0.5469 - val_loss: 0.7913 - val_accuracy: 0.4375\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7246 - accuracy: 0.5312 - val_loss: 0.7859 - val_accuracy: 0.4375\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7261 - accuracy: 0.5469 - val_loss: 0.7752 - val_accuracy: 0.3750\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7189 - accuracy: 0.5781 - val_loss: 0.7807 - val_accuracy: 0.3750\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7170 - accuracy: 0.5469 - val_loss: 0.7959 - val_accuracy: 0.4375\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7199 - accuracy: 0.5781 - val_loss: 0.8126 - val_accuracy: 0.4375\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7259 - accuracy: 0.5312 - val_loss: 0.8209 - val_accuracy: 0.3750\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7299 - accuracy: 0.5312 - val_loss: 0.8022 - val_accuracy: 0.4375\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7187 - accuracy: 0.5781 - val_loss: 0.7667 - val_accuracy: 0.3750\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7137 - accuracy: 0.5625 - val_loss: 0.7526 - val_accuracy: 0.5000\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7159 - accuracy: 0.5938 - val_loss: 0.7490 - val_accuracy: 0.5000\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7209 - accuracy: 0.5469 - val_loss: 0.7474 - val_accuracy: 0.5625\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7247 - accuracy: 0.5469 - val_loss: 0.7463 - val_accuracy: 0.5625\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7238 - accuracy: 0.5469 - val_loss: 0.7466 - val_accuracy: 0.5000\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7136 - accuracy: 0.5781 - val_loss: 0.7498 - val_accuracy: 0.5000\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7055 - accuracy: 0.5781 - val_loss: 0.7650 - val_accuracy: 0.3750\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7081 - accuracy: 0.5938 - val_loss: 0.7907 - val_accuracy: 0.4375\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7133 - accuracy: 0.5938 - val_loss: 0.7857 - val_accuracy: 0.4375\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7126 - accuracy: 0.5469 - val_loss: 0.7663 - val_accuracy: 0.3750\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7024 - accuracy: 0.6094 - val_loss: 0.7565 - val_accuracy: 0.3750\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7028 - accuracy: 0.5781 - val_loss: 0.7497 - val_accuracy: 0.5000\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7013 - accuracy: 0.5781 - val_loss: 0.7545 - val_accuracy: 0.4375\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7046 - accuracy: 0.6094 - val_loss: 0.7626 - val_accuracy: 0.3750\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6987 - accuracy: 0.5938 - val_loss: 0.7514 - val_accuracy: 0.5000\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6971 - accuracy: 0.6250 - val_loss: 0.7410 - val_accuracy: 0.5000\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.5625 - val_loss: 0.7387 - val_accuracy: 0.5000\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6994 - accuracy: 0.5625 - val_loss: 0.7438 - val_accuracy: 0.5000\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6975 - accuracy: 0.5781 - val_loss: 0.7528 - val_accuracy: 0.3750\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6941 - accuracy: 0.6094 - val_loss: 0.7562 - val_accuracy: 0.3750\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6943 - accuracy: 0.5938 - val_loss: 0.7533 - val_accuracy: 0.3750\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6922 - accuracy: 0.6094 - val_loss: 0.7436 - val_accuracy: 0.5000\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6919 - accuracy: 0.6250 - val_loss: 0.7369 - val_accuracy: 0.5000\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5938 - val_loss: 0.7371 - val_accuracy: 0.5000\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5938 - val_loss: 0.7452 - val_accuracy: 0.5000\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.6094 - val_loss: 0.7572 - val_accuracy: 0.3750\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6955 - accuracy: 0.5625 - val_loss: 0.7600 - val_accuracy: 0.3750\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.5938 - val_loss: 0.7410 - val_accuracy: 0.5000\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6844 - accuracy: 0.6094 - val_loss: 0.7284 - val_accuracy: 0.5000\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.5625 - val_loss: 0.7242 - val_accuracy: 0.5000\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5938 - val_loss: 0.7251 - val_accuracy: 0.5000\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5625 - val_loss: 0.7307 - val_accuracy: 0.5000\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.6094 - val_loss: 0.7416 - val_accuracy: 0.4375\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5781 - val_loss: 0.7552 - val_accuracy: 0.3750\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6910 - accuracy: 0.6094 - val_loss: 0.7351 - val_accuracy: 0.5000\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6765 - accuracy: 0.6250 - val_loss: 0.7170 - val_accuracy: 0.5625\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6963 - accuracy: 0.5625 - val_loss: 0.7188 - val_accuracy: 0.5625\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7054 - accuracy: 0.5938 - val_loss: 0.7153 - val_accuracy: 0.5000\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5781 - val_loss: 0.7168 - val_accuracy: 0.5000\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5938 - val_loss: 0.7460 - val_accuracy: 0.3750\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.6094 - val_loss: 0.7706 - val_accuracy: 0.4375\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5312 - val_loss: 0.7528 - val_accuracy: 0.4375\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6824 - accuracy: 0.6250 - val_loss: 0.7223 - val_accuracy: 0.5000\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5781 - val_loss: 0.7109 - val_accuracy: 0.5000\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6737 - accuracy: 0.6094 - val_loss: 0.7135 - val_accuracy: 0.5000\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.6094 - val_loss: 0.7179 - val_accuracy: 0.5000\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6725 - accuracy: 0.5781 - val_loss: 0.7162 - val_accuracy: 0.5000\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6695 - accuracy: 0.5938 - val_loss: 0.7062 - val_accuracy: 0.5000\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6755 - accuracy: 0.6562 - val_loss: 0.7018 - val_accuracy: 0.5000\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6745 - accuracy: 0.5938 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6674 - accuracy: 0.6094 - val_loss: 0.7178 - val_accuracy: 0.5000\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6703 - accuracy: 0.5938 - val_loss: 0.7546 - val_accuracy: 0.4375\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6845 - accuracy: 0.5625 - val_loss: 0.7588 - val_accuracy: 0.4375\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.5781 - val_loss: 0.7371 - val_accuracy: 0.3750\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6749 - accuracy: 0.6250 - val_loss: 0.7177 - val_accuracy: 0.5000\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6724 - accuracy: 0.5781 - val_loss: 0.7094 - val_accuracy: 0.5000\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6644 - accuracy: 0.6094 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6630 - accuracy: 0.5938 - val_loss: 0.7044 - val_accuracy: 0.5000\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6678 - accuracy: 0.6250 - val_loss: 0.7044 - val_accuracy: 0.5000\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6594 - accuracy: 0.6094 - val_loss: 0.7230 - val_accuracy: 0.4375\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6682 - accuracy: 0.6094 - val_loss: 0.7405 - val_accuracy: 0.4375\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.6094 - val_loss: 0.7264 - val_accuracy: 0.4375\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6713 - accuracy: 0.5938 - val_loss: 0.7066 - val_accuracy: 0.5000\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6609 - accuracy: 0.6250 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6578 - accuracy: 0.6094 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6573 - accuracy: 0.6406 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.5938 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6681 - accuracy: 0.5938 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6645 - accuracy: 0.5938 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6637 - accuracy: 0.5938 - val_loss: 0.6847 - val_accuracy: 0.5000\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6593 - accuracy: 0.6250 - val_loss: 0.6858 - val_accuracy: 0.5000\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6565 - accuracy: 0.6406 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.6250 - val_loss: 0.6896 - val_accuracy: 0.5000\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6525 - accuracy: 0.6406 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6570 - accuracy: 0.5938 - val_loss: 0.7115 - val_accuracy: 0.5000\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6609 - accuracy: 0.6094 - val_loss: 0.7050 - val_accuracy: 0.5000\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6565 - accuracy: 0.6094 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6552 - accuracy: 0.6094 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6513 - accuracy: 0.6406 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.6406 - val_loss: 0.6802 - val_accuracy: 0.5000\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6500 - accuracy: 0.6562 - val_loss: 0.6764 - val_accuracy: 0.5000\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6520 - accuracy: 0.6250 - val_loss: 0.6750 - val_accuracy: 0.5000\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6585 - accuracy: 0.6094 - val_loss: 0.6764 - val_accuracy: 0.5000\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6671 - accuracy: 0.5938 - val_loss: 0.6776 - val_accuracy: 0.5625\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6704 - accuracy: 0.5938 - val_loss: 0.6734 - val_accuracy: 0.5000\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6594 - accuracy: 0.6250 - val_loss: 0.6749 - val_accuracy: 0.5000\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6481 - accuracy: 0.6562 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.6094 - val_loss: 0.7007 - val_accuracy: 0.6250\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6552 - accuracy: 0.6250 - val_loss: 0.6914 - val_accuracy: 0.5625\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6507 - accuracy: 0.6094 - val_loss: 0.6750 - val_accuracy: 0.5000\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6439 - accuracy: 0.6250 - val_loss: 0.6687 - val_accuracy: 0.5000\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6493 - accuracy: 0.6250 - val_loss: 0.6694 - val_accuracy: 0.5000\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6587 - accuracy: 0.6094 - val_loss: 0.6690 - val_accuracy: 0.5000\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6588 - accuracy: 0.6094 - val_loss: 0.6671 - val_accuracy: 0.5000\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6510 - accuracy: 0.6094 - val_loss: 0.6684 - val_accuracy: 0.5000\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6451 - accuracy: 0.6406 - val_loss: 0.6731 - val_accuracy: 0.5000\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6425 - accuracy: 0.6250 - val_loss: 0.6782 - val_accuracy: 0.5000\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6450 - accuracy: 0.6094 - val_loss: 0.6912 - val_accuracy: 0.6250\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6521 - accuracy: 0.5938 - val_loss: 0.7087 - val_accuracy: 0.6250\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6602 - accuracy: 0.5938 - val_loss: 0.6904 - val_accuracy: 0.6250\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6460 - accuracy: 0.5781 - val_loss: 0.6698 - val_accuracy: 0.5000\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6370 - accuracy: 0.6250 - val_loss: 0.6638 - val_accuracy: 0.5000\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6498 - accuracy: 0.6094 - val_loss: 0.6715 - val_accuracy: 0.5625\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6733 - accuracy: 0.5781 - val_loss: 0.6707 - val_accuracy: 0.5625\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6700 - accuracy: 0.5938 - val_loss: 0.6616 - val_accuracy: 0.5000\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6419 - accuracy: 0.6094 - val_loss: 0.6702 - val_accuracy: 0.5625\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6481 - accuracy: 0.6094 - val_loss: 0.7044 - val_accuracy: 0.6250\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6583 - accuracy: 0.6094 - val_loss: 0.6916 - val_accuracy: 0.6250\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6479 - accuracy: 0.5938 - val_loss: 0.6650 - val_accuracy: 0.5625\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6313 - accuracy: 0.6250 - val_loss: 0.6577 - val_accuracy: 0.5000\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6609 - accuracy: 0.5781 - val_loss: 0.6683 - val_accuracy: 0.5625\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6714 - accuracy: 0.5625 - val_loss: 0.6610 - val_accuracy: 0.5000\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6550 - accuracy: 0.5938 - val_loss: 0.6543 - val_accuracy: 0.5000\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6346 - accuracy: 0.6562 - val_loss: 0.6786 - val_accuracy: 0.6250\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6424 - accuracy: 0.6094 - val_loss: 0.7206 - val_accuracy: 0.5625\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.6719 - val_loss: 0.6991 - val_accuracy: 0.6250\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6525 - accuracy: 0.6094 - val_loss: 0.6538 - val_accuracy: 0.5625\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6309 - accuracy: 0.6250 - val_loss: 0.6552 - val_accuracy: 0.5000\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6600 - accuracy: 0.6094 - val_loss: 0.6645 - val_accuracy: 0.5625\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6724 - accuracy: 0.5625 - val_loss: 0.6549 - val_accuracy: 0.5000\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6566 - accuracy: 0.6094 - val_loss: 0.6468 - val_accuracy: 0.4375\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6338 - accuracy: 0.6406 - val_loss: 0.6590 - val_accuracy: 0.6250\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6343 - accuracy: 0.6250 - val_loss: 0.6855 - val_accuracy: 0.6250\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6554 - accuracy: 0.6250 - val_loss: 0.6749 - val_accuracy: 0.6250\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6442 - accuracy: 0.6094 - val_loss: 0.6473 - val_accuracy: 0.5625\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6309 - accuracy: 0.6250 - val_loss: 0.6447 - val_accuracy: 0.5000\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.6250 - val_loss: 0.6469 - val_accuracy: 0.5000\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6459 - accuracy: 0.6250 - val_loss: 0.6441 - val_accuracy: 0.5000\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6379 - accuracy: 0.6562 - val_loss: 0.6469 - val_accuracy: 0.5625\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6310 - accuracy: 0.6250 - val_loss: 0.6582 - val_accuracy: 0.6250\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.5938 - val_loss: 0.6760 - val_accuracy: 0.6250\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6510 - accuracy: 0.6094 - val_loss: 0.6891 - val_accuracy: 0.6250\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6625 - accuracy: 0.6406 - val_loss: 0.6622 - val_accuracy: 0.6250\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6350 - accuracy: 0.6094 - val_loss: 0.6494 - val_accuracy: 0.6250\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6301 - accuracy: 0.6094 - val_loss: 0.6422 - val_accuracy: 0.5625\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6354 - accuracy: 0.6406 - val_loss: 0.6416 - val_accuracy: 0.5625\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6281 - accuracy: 0.6406 - val_loss: 0.6498 - val_accuracy: 0.6250\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6304 - accuracy: 0.6562 - val_loss: 0.6604 - val_accuracy: 0.6250\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6366 - accuracy: 0.6250 - val_loss: 0.6598 - val_accuracy: 0.6250\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6361 - accuracy: 0.6250 - val_loss: 0.6494 - val_accuracy: 0.6250\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6330 - accuracy: 0.6250 - val_loss: 0.6387 - val_accuracy: 0.5625\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6333 - accuracy: 0.6094 - val_loss: 0.6386 - val_accuracy: 0.6250\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6432 - val_accuracy: 0.6250\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6268 - accuracy: 0.6250 - val_loss: 0.6403 - val_accuracy: 0.6250\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6256 - accuracy: 0.6406 - val_loss: 0.6384 - val_accuracy: 0.6250\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6257 - accuracy: 0.6406 - val_loss: 0.6379 - val_accuracy: 0.6250\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6260 - accuracy: 0.6094 - val_loss: 0.6374 - val_accuracy: 0.6250\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6243 - accuracy: 0.6406 - val_loss: 0.6337 - val_accuracy: 0.6250\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6257 - accuracy: 0.6406 - val_loss: 0.6327 - val_accuracy: 0.5000\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6291 - accuracy: 0.6250 - val_loss: 0.6319 - val_accuracy: 0.5000\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6262 - accuracy: 0.6406 - val_loss: 0.6333 - val_accuracy: 0.6250\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6219 - accuracy: 0.6562 - val_loss: 0.6428 - val_accuracy: 0.6250\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6311 - accuracy: 0.6250 - val_loss: 0.6509 - val_accuracy: 0.6250\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6357 - accuracy: 0.5938 - val_loss: 0.6383 - val_accuracy: 0.6250\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6248 - accuracy: 0.6094 - val_loss: 0.6277 - val_accuracy: 0.6250\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6248 - accuracy: 0.6562 - val_loss: 0.6364 - val_accuracy: 0.5000\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6468 - accuracy: 0.6094 - val_loss: 0.6410 - val_accuracy: 0.5625\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6507 - accuracy: 0.5938 - val_loss: 0.6309 - val_accuracy: 0.5000\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6312 - accuracy: 0.6250 - val_loss: 0.6295 - val_accuracy: 0.6250\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6220 - accuracy: 0.6250 - val_loss: 0.6531 - val_accuracy: 0.6250\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6386 - accuracy: 0.6094 - val_loss: 0.6630 - val_accuracy: 0.6250\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6466 - accuracy: 0.6094 - val_loss: 0.6425 - val_accuracy: 0.6250\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6261 - accuracy: 0.6250 - val_loss: 0.6268 - val_accuracy: 0.6250\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6277 - accuracy: 0.6562 - val_loss: 0.6292 - val_accuracy: 0.5000\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6327 - accuracy: 0.6406 - val_loss: 0.6290 - val_accuracy: 0.5000\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6325 - accuracy: 0.6406 - val_loss: 0.6261 - val_accuracy: 0.5000\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.6094 - val_loss: 0.6255 - val_accuracy: 0.6250\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6223 - accuracy: 0.6562 - val_loss: 0.6258 - val_accuracy: 0.6250\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6225 - accuracy: 0.6562 - val_loss: 0.6280 - val_accuracy: 0.6250\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6192 - accuracy: 0.6094 - val_loss: 0.6406 - val_accuracy: 0.6250\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6304 - accuracy: 0.6250 - val_loss: 0.6452 - val_accuracy: 0.6250\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6309 - accuracy: 0.6250 - val_loss: 0.6302 - val_accuracy: 0.6250\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6182 - accuracy: 0.6250 - val_loss: 0.6250 - val_accuracy: 0.5625\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6311 - accuracy: 0.6094 - val_loss: 0.6278 - val_accuracy: 0.5625\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6299 - accuracy: 0.6719 - val_loss: 0.6236 - val_accuracy: 0.5625\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6246 - accuracy: 0.5938 - val_loss: 0.6266 - val_accuracy: 0.6250\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6208 - accuracy: 0.6250 - val_loss: 0.6285 - val_accuracy: 0.6250\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6213 - accuracy: 0.6094 - val_loss: 0.6235 - val_accuracy: 0.6250\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6208 - accuracy: 0.6406 - val_loss: 0.6221 - val_accuracy: 0.5625\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6219 - accuracy: 0.6250 - val_loss: 0.6219 - val_accuracy: 0.5625\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6222 - accuracy: 0.6406 - val_loss: 0.6216 - val_accuracy: 0.5625\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6190 - accuracy: 0.6719 - val_loss: 0.6228 - val_accuracy: 0.6250\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6173 - accuracy: 0.6406 - val_loss: 0.6290 - val_accuracy: 0.6250\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6220 - accuracy: 0.6250 - val_loss: 0.6329 - val_accuracy: 0.6250\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6242 - accuracy: 0.6094 - val_loss: 0.6257 - val_accuracy: 0.6250\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6181 - accuracy: 0.6094 - val_loss: 0.6210 - val_accuracy: 0.5625\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6168 - accuracy: 0.6719 - val_loss: 0.6252 - val_accuracy: 0.5625\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6318 - accuracy: 0.6719 - val_loss: 0.6331 - val_accuracy: 0.5000\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6397 - accuracy: 0.6406 - val_loss: 0.6256 - val_accuracy: 0.5625\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6247 - accuracy: 0.6875 - val_loss: 0.6216 - val_accuracy: 0.6250\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6193 - accuracy: 0.6406 - val_loss: 0.6394 - val_accuracy: 0.6250\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6307 - accuracy: 0.6250 - val_loss: 0.6420 - val_accuracy: 0.6250\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6328 - accuracy: 0.6094 - val_loss: 0.6281 - val_accuracy: 0.6250\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6166 - accuracy: 0.6250 - val_loss: 0.6204 - val_accuracy: 0.5625\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6323 - accuracy: 0.6875 - val_loss: 0.6283 - val_accuracy: 0.5000\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6341 - accuracy: 0.6406 - val_loss: 0.6241 - val_accuracy: 0.5625\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6265 - accuracy: 0.6406 - val_loss: 0.6198 - val_accuracy: 0.5625\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6177 - accuracy: 0.6875 - val_loss: 0.6200 - val_accuracy: 0.6250\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6158 - accuracy: 0.6250 - val_loss: 0.6281 - val_accuracy: 0.6250\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6221 - accuracy: 0.6094 - val_loss: 0.6284 - val_accuracy: 0.6250\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6211 - accuracy: 0.5938 - val_loss: 0.6196 - val_accuracy: 0.6250\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6211 - accuracy: 0.6094 - val_loss: 0.6175 - val_accuracy: 0.5625\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6184 - accuracy: 0.6719 - val_loss: 0.6180 - val_accuracy: 0.5625\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6187 - accuracy: 0.6406 - val_loss: 0.6195 - val_accuracy: 0.5625\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6199 - accuracy: 0.6250 - val_loss: 0.6177 - val_accuracy: 0.5625\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6194 - accuracy: 0.6875 - val_loss: 0.6177 - val_accuracy: 0.5625\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6145 - accuracy: 0.6406 - val_loss: 0.6175 - val_accuracy: 0.5625\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6144 - accuracy: 0.6562 - val_loss: 0.6176 - val_accuracy: 0.5625\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6158 - accuracy: 0.6719 - val_loss: 0.6191 - val_accuracy: 0.5625\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6191 - accuracy: 0.6406 - val_loss: 0.6229 - val_accuracy: 0.5625\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6267 - accuracy: 0.6719 - val_loss: 0.6234 - val_accuracy: 0.5625\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6260 - accuracy: 0.6562 - val_loss: 0.6178 - val_accuracy: 0.6250\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6184 - accuracy: 0.6875 - val_loss: 0.6181 - val_accuracy: 0.6250\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.6094 - val_loss: 0.6201 - val_accuracy: 0.6250\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6146 - accuracy: 0.6094 - val_loss: 0.6199 - val_accuracy: 0.6250\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6141 - accuracy: 0.6094 - val_loss: 0.6184 - val_accuracy: 0.6250\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6131 - accuracy: 0.6094 - val_loss: 0.6176 - val_accuracy: 0.5625\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6144 - accuracy: 0.6562 - val_loss: 0.6179 - val_accuracy: 0.5625\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6143 - accuracy: 0.6562 - val_loss: 0.6187 - val_accuracy: 0.5625\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6144 - accuracy: 0.6094 - val_loss: 0.6241 - val_accuracy: 0.6250\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6171 - accuracy: 0.6094 - val_loss: 0.6220 - val_accuracy: 0.6250\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6140 - accuracy: 0.5938 - val_loss: 0.6174 - val_accuracy: 0.5625\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6149 - accuracy: 0.6719 - val_loss: 0.6185 - val_accuracy: 0.6250\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6179 - accuracy: 0.6562 - val_loss: 0.6173 - val_accuracy: 0.5625\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.6562 - val_loss: 0.6244 - val_accuracy: 0.6250\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6159 - accuracy: 0.6094 - val_loss: 0.6424 - val_accuracy: 0.6250\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6371 - accuracy: 0.6250 - val_loss: 0.6327 - val_accuracy: 0.6250\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6276 - accuracy: 0.6094 - val_loss: 0.6180 - val_accuracy: 0.5625\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6095 - accuracy: 0.6406 - val_loss: 0.6228 - val_accuracy: 0.5625\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6219 - accuracy: 0.6719 - val_loss: 0.6384 - val_accuracy: 0.5625\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6448 - accuracy: 0.6094 - val_loss: 0.6364 - val_accuracy: 0.5625\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6414 - accuracy: 0.6406 - val_loss: 0.6221 - val_accuracy: 0.5625\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6188 - accuracy: 0.6406 - val_loss: 0.6191 - val_accuracy: 0.5625\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6146 - accuracy: 0.5938 - val_loss: 0.6253 - val_accuracy: 0.6250\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6179 - accuracy: 0.6250 - val_loss: 0.6198 - val_accuracy: 0.6250\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6189 - accuracy: 0.6094 - val_loss: 0.6167 - val_accuracy: 0.5625\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6127 - accuracy: 0.6562 - val_loss: 0.6163 - val_accuracy: 0.5625\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6125 - accuracy: 0.6562 - val_loss: 0.6162 - val_accuracy: 0.5625\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6133 - accuracy: 0.6719 - val_loss: 0.6155 - val_accuracy: 0.5625\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6105 - accuracy: 0.6562 - val_loss: 0.6175 - val_accuracy: 0.6250\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6204 - accuracy: 0.6094 - val_loss: 0.6176 - val_accuracy: 0.6250\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6095 - accuracy: 0.5938 - val_loss: 0.6160 - val_accuracy: 0.6250\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6082 - accuracy: 0.7031 - val_loss: 0.6408 - val_accuracy: 0.6250\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6572 - accuracy: 0.6094 - val_loss: 0.6651 - val_accuracy: 0.6250\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6789 - accuracy: 0.5938 - val_loss: 0.6369 - val_accuracy: 0.5625\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6516 - accuracy: 0.6094 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6189 - accuracy: 0.6250 - val_loss: 0.6206 - val_accuracy: 0.6250\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6195 - accuracy: 0.6406 - val_loss: 0.6195 - val_accuracy: 0.6250\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6187 - accuracy: 0.6250 - val_loss: 0.6131 - val_accuracy: 0.5625\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6060 - accuracy: 0.6250 - val_loss: 0.6210 - val_accuracy: 0.5625\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6257 - accuracy: 0.6875 - val_loss: 0.6365 - val_accuracy: 0.5625\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6439 - accuracy: 0.6562 - val_loss: 0.6327 - val_accuracy: 0.5625\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6410 - accuracy: 0.6562 - val_loss: 0.6236 - val_accuracy: 0.5625\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6232 - accuracy: 0.6562 - val_loss: 0.6150 - val_accuracy: 0.5625\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6059 - accuracy: 0.6719 - val_loss: 0.6254 - val_accuracy: 0.6250\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6532 - accuracy: 0.5938 - val_loss: 0.6197 - val_accuracy: 0.6250\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6087 - accuracy: 0.6406 - val_loss: 0.6306 - val_accuracy: 0.5625\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6484 - accuracy: 0.6250 - val_loss: 0.6548 - val_accuracy: 0.6250\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6651 - accuracy: 0.5781 - val_loss: 0.6365 - val_accuracy: 0.5625\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.6406 - val_loss: 0.6156 - val_accuracy: 0.5625\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6153 - accuracy: 0.6562 - val_loss: 0.6223 - val_accuracy: 0.6250\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6185 - accuracy: 0.6406 - val_loss: 0.6319 - val_accuracy: 0.6250\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6290 - accuracy: 0.6250 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6181 - accuracy: 0.6250 - val_loss: 0.6143 - val_accuracy: 0.5625\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6090 - accuracy: 0.6250 - val_loss: 0.6148 - val_accuracy: 0.5625\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6119 - accuracy: 0.6719 - val_loss: 0.6173 - val_accuracy: 0.6250\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6165 - accuracy: 0.6562 - val_loss: 0.6181 - val_accuracy: 0.5625\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6165 - accuracy: 0.6562 - val_loss: 0.6190 - val_accuracy: 0.5625\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.6562 - val_loss: 0.6175 - val_accuracy: 0.5625\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6146 - accuracy: 0.6562 - val_loss: 0.6153 - val_accuracy: 0.5625\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6152 - accuracy: 0.6562 - val_loss: 0.6148 - val_accuracy: 0.5625\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6103 - accuracy: 0.6406 - val_loss: 0.6145 - val_accuracy: 0.5625\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6100 - accuracy: 0.6406 - val_loss: 0.6143 - val_accuracy: 0.5625\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6095 - accuracy: 0.6406 - val_loss: 0.6147 - val_accuracy: 0.5625\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6147 - accuracy: 0.6250 - val_loss: 0.6143 - val_accuracy: 0.5625\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6112 - accuracy: 0.6250 - val_loss: 0.6149 - val_accuracy: 0.5625\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6119 - accuracy: 0.6406 - val_loss: 0.6146 - val_accuracy: 0.5625\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6110 - accuracy: 0.6719 - val_loss: 0.6134 - val_accuracy: 0.5625\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6100 - accuracy: 0.6250 - val_loss: 0.6136 - val_accuracy: 0.5625\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6097 - accuracy: 0.6094 - val_loss: 0.6125 - val_accuracy: 0.5625\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6079 - accuracy: 0.6406 - val_loss: 0.6145 - val_accuracy: 0.5625\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6115 - accuracy: 0.6875 - val_loss: 0.6244 - val_accuracy: 0.5625\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6284 - accuracy: 0.6406 - val_loss: 0.6260 - val_accuracy: 0.6250\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6320 - accuracy: 0.6406 - val_loss: 0.6164 - val_accuracy: 0.5625\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6150 - accuracy: 0.6562 - val_loss: 0.6106 - val_accuracy: 0.5625\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6039 - accuracy: 0.6562 - val_loss: 0.6345 - val_accuracy: 0.6250\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6416 - accuracy: 0.6562 - val_loss: 0.6409 - val_accuracy: 0.6250\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6446 - accuracy: 0.6562 - val_loss: 0.6116 - val_accuracy: 0.6250\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6082 - accuracy: 0.6562 - val_loss: 0.6162 - val_accuracy: 0.5625\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6240 - accuracy: 0.6562 - val_loss: 0.6254 - val_accuracy: 0.6250\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6284 - accuracy: 0.6406 - val_loss: 0.6151 - val_accuracy: 0.6250\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6122 - accuracy: 0.6875 - val_loss: 0.6110 - val_accuracy: 0.5625\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6208 - accuracy: 0.6094 - val_loss: 0.6166 - val_accuracy: 0.6250\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6195 - accuracy: 0.6094 - val_loss: 0.6110 - val_accuracy: 0.5625\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6082 - accuracy: 0.6094 - val_loss: 0.6107 - val_accuracy: 0.5625\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6076 - accuracy: 0.6719 - val_loss: 0.6133 - val_accuracy: 0.5625\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6117 - accuracy: 0.6719 - val_loss: 0.6189 - val_accuracy: 0.5625\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6199 - accuracy: 0.6406 - val_loss: 0.6229 - val_accuracy: 0.5625\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6244 - accuracy: 0.6406 - val_loss: 0.6148 - val_accuracy: 0.5625\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6168 - accuracy: 0.6719 - val_loss: 0.6125 - val_accuracy: 0.6250\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6086 - accuracy: 0.5938 - val_loss: 0.6177 - val_accuracy: 0.6250\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6153 - accuracy: 0.6406 - val_loss: 0.6156 - val_accuracy: 0.6250\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6134 - accuracy: 0.5938 - val_loss: 0.6124 - val_accuracy: 0.5625\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6080 - accuracy: 0.6406 - val_loss: 0.6131 - val_accuracy: 0.5625\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6088 - accuracy: 0.6562 - val_loss: 0.6134 - val_accuracy: 0.5625\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6093 - accuracy: 0.6719 - val_loss: 0.6136 - val_accuracy: 0.5625\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6095 - accuracy: 0.6719 - val_loss: 0.6135 - val_accuracy: 0.5625\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6094 - accuracy: 0.6719 - val_loss: 0.6130 - val_accuracy: 0.5625\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6089 - accuracy: 0.6562 - val_loss: 0.6131 - val_accuracy: 0.5625\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.6094 - val_loss: 0.6158 - val_accuracy: 0.6250\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6106 - accuracy: 0.5938 - val_loss: 0.6121 - val_accuracy: 0.5625\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6133 - accuracy: 0.6562 - val_loss: 0.6116 - val_accuracy: 0.5625\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6070 - accuracy: 0.6250 - val_loss: 0.6121 - val_accuracy: 0.6250\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6089 - accuracy: 0.5938 - val_loss: 0.6149 - val_accuracy: 0.6250\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6128 - accuracy: 0.6250 - val_loss: 0.6112 - val_accuracy: 0.6250\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6075 - accuracy: 0.6250 - val_loss: 0.6095 - val_accuracy: 0.5625\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6091 - accuracy: 0.6406 - val_loss: 0.6148 - val_accuracy: 0.5625\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6168 - accuracy: 0.6406 - val_loss: 0.6121 - val_accuracy: 0.5625\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6168 - accuracy: 0.6406 - val_loss: 0.6076 - val_accuracy: 0.5625\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6074 - accuracy: 0.6406 - val_loss: 0.6076 - val_accuracy: 0.5625\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6159 - accuracy: 0.6250 - val_loss: 0.6080 - val_accuracy: 0.5625\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6090 - accuracy: 0.6250 - val_loss: 0.6084 - val_accuracy: 0.5625\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6117 - accuracy: 0.6562 - val_loss: 0.6093 - val_accuracy: 0.5625\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6080 - accuracy: 0.6406 - val_loss: 0.6077 - val_accuracy: 0.5625\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6116 - accuracy: 0.6094 - val_loss: 0.6109 - val_accuracy: 0.6250\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6104 - accuracy: 0.6094 - val_loss: 0.6080 - val_accuracy: 0.5625\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6076 - accuracy: 0.6250 - val_loss: 0.6121 - val_accuracy: 0.5625\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6113 - accuracy: 0.6719 - val_loss: 0.6140 - val_accuracy: 0.5625\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6123 - accuracy: 0.6719 - val_loss: 0.6103 - val_accuracy: 0.5625\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6078 - accuracy: 0.6562 - val_loss: 0.6096 - val_accuracy: 0.5625\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6091 - accuracy: 0.6250 - val_loss: 0.6112 - val_accuracy: 0.6250\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6103 - accuracy: 0.6094 - val_loss: 0.6089 - val_accuracy: 0.5625\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6072 - accuracy: 0.6094 - val_loss: 0.6090 - val_accuracy: 0.5625\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6073 - accuracy: 0.6406 - val_loss: 0.6097 - val_accuracy: 0.5625\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6138 - accuracy: 0.6094 - val_loss: 0.6121 - val_accuracy: 0.5625\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6144 - accuracy: 0.6719 - val_loss: 0.6200 - val_accuracy: 0.5625\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6210 - accuracy: 0.6406 - val_loss: 0.6114 - val_accuracy: 0.5625\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6221 - accuracy: 0.6719 - val_loss: 0.6062 - val_accuracy: 0.5625\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6068 - accuracy: 0.6406 - val_loss: 0.6058 - val_accuracy: 0.5625\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6071 - accuracy: 0.6250 - val_loss: 0.6052 - val_accuracy: 0.5625\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6071 - accuracy: 0.6250 - val_loss: 0.6046 - val_accuracy: 0.5625\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6062 - accuracy: 0.6406 - val_loss: 0.6043 - val_accuracy: 0.5625\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6069 - accuracy: 0.6094 - val_loss: 0.6051 - val_accuracy: 0.6250\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6094 - accuracy: 0.6250 - val_loss: 0.6060 - val_accuracy: 0.6250\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6124 - accuracy: 0.6250 - val_loss: 0.6042 - val_accuracy: 0.6250\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6088 - accuracy: 0.6250 - val_loss: 0.6035 - val_accuracy: 0.5625\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6045 - accuracy: 0.6406 - val_loss: 0.6081 - val_accuracy: 0.5625\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6131 - accuracy: 0.6719 - val_loss: 0.6127 - val_accuracy: 0.5625\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6169 - accuracy: 0.6406 - val_loss: 0.6069 - val_accuracy: 0.5625\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6080 - accuracy: 0.6562 - val_loss: 0.6028 - val_accuracy: 0.5625\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6040 - accuracy: 0.6406 - val_loss: 0.6153 - val_accuracy: 0.6250\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6373 - accuracy: 0.6406 - val_loss: 0.6040 - val_accuracy: 0.6250\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6124 - accuracy: 0.6250 - val_loss: 0.6188 - val_accuracy: 0.6250\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6304 - accuracy: 0.6406 - val_loss: 0.6325 - val_accuracy: 0.6250\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6436 - accuracy: 0.6406 - val_loss: 0.6198 - val_accuracy: 0.6250\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6244 - accuracy: 0.6406 - val_loss: 0.6062 - val_accuracy: 0.5625\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6039 - accuracy: 0.6875 - val_loss: 0.6080 - val_accuracy: 0.6250\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6111 - accuracy: 0.6250 - val_loss: 0.6335 - val_accuracy: 0.6875\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6535 - accuracy: 0.6562 - val_loss: 0.6050 - val_accuracy: 0.6250\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5972 - accuracy: 0.6719 - val_loss: 0.6349 - val_accuracy: 0.6250\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6523 - accuracy: 0.6250 - val_loss: 0.6751 - val_accuracy: 0.6250\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6947 - accuracy: 0.5781 - val_loss: 0.6580 - val_accuracy: 0.6250\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6659 - accuracy: 0.5938 - val_loss: 0.6132 - val_accuracy: 0.5625\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6080 - accuracy: 0.6250 - val_loss: 0.6190 - val_accuracy: 0.6250\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6204 - accuracy: 0.6562 - val_loss: 0.6998 - val_accuracy: 0.6875\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9275 - accuracy: 0.6406 - val_loss: 0.6270 - val_accuracy: 0.6875\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6224 - accuracy: 0.6562 - val_loss: 0.6121 - val_accuracy: 0.5625\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6416 - accuracy: 0.6250 - val_loss: 0.6519 - val_accuracy: 0.6250\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6694 - accuracy: 0.5781 - val_loss: 0.6313 - val_accuracy: 0.6250\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6311 - accuracy: 0.6406 - val_loss: 0.6022 - val_accuracy: 0.5625\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6135 - accuracy: 0.6406 - val_loss: 0.6404 - val_accuracy: 0.6875\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6653 - accuracy: 0.6562 - val_loss: 0.6034 - val_accuracy: 0.6250\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6219 - accuracy: 0.6094 - val_loss: 0.6249 - val_accuracy: 0.6250\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.6562 - val_loss: 0.6468 - val_accuracy: 0.6250\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6653 - accuracy: 0.5781 - val_loss: 0.6295 - val_accuracy: 0.6250\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6344 - accuracy: 0.6562 - val_loss: 0.5992 - val_accuracy: 0.5625\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6206 - accuracy: 0.6250 - val_loss: 0.6219 - val_accuracy: 0.6875\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6385 - accuracy: 0.6562 - val_loss: 0.6239 - val_accuracy: 0.6875\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6405 - accuracy: 0.6562 - val_loss: 0.6050 - val_accuracy: 0.6250\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6187 - accuracy: 0.5938 - val_loss: 0.5963 - val_accuracy: 0.5625\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6055 - accuracy: 0.6250 - val_loss: 0.5976 - val_accuracy: 0.5625\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6084 - accuracy: 0.6719 - val_loss: 0.5975 - val_accuracy: 0.5625\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6067 - accuracy: 0.6562 - val_loss: 0.5959 - val_accuracy: 0.6250\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6118 - accuracy: 0.5781 - val_loss: 0.5974 - val_accuracy: 0.6250\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6077 - accuracy: 0.6094 - val_loss: 0.5956 - val_accuracy: 0.5625\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6052 - accuracy: 0.6406 - val_loss: 0.5962 - val_accuracy: 0.5625\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6068 - accuracy: 0.6406 - val_loss: 0.5959 - val_accuracy: 0.5625\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6066 - accuracy: 0.6406 - val_loss: 0.5958 - val_accuracy: 0.6250\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6052 - accuracy: 0.6094 - val_loss: 0.5960 - val_accuracy: 0.6250\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6052 - accuracy: 0.6094 - val_loss: 0.5963 - val_accuracy: 0.5625\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6060 - accuracy: 0.6406 - val_loss: 0.5973 - val_accuracy: 0.5625\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6063 - accuracy: 0.6719 - val_loss: 0.5963 - val_accuracy: 0.5625\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6043 - accuracy: 0.6406 - val_loss: 0.5973 - val_accuracy: 0.6250\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6103 - accuracy: 0.5938 - val_loss: 0.6001 - val_accuracy: 0.6250\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6142 - accuracy: 0.5938 - val_loss: 0.5977 - val_accuracy: 0.6250\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6067 - accuracy: 0.5938 - val_loss: 0.5981 - val_accuracy: 0.6250\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6072 - accuracy: 0.5938 - val_loss: 0.5971 - val_accuracy: 0.5625\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6034 - accuracy: 0.6406 - val_loss: 0.6029 - val_accuracy: 0.6250\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6133 - accuracy: 0.6875 - val_loss: 0.6080 - val_accuracy: 0.5625\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6191 - accuracy: 0.6562 - val_loss: 0.6033 - val_accuracy: 0.6250\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6126 - accuracy: 0.6719 - val_loss: 0.5976 - val_accuracy: 0.5625\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6086 - accuracy: 0.6406 - val_loss: 0.5966 - val_accuracy: 0.6250\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6050 - accuracy: 0.6094 - val_loss: 0.5962 - val_accuracy: 0.5625\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6048 - accuracy: 0.6250 - val_loss: 0.5963 - val_accuracy: 0.5625\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6050 - accuracy: 0.6406 - val_loss: 0.5967 - val_accuracy: 0.5625\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6055 - accuracy: 0.6406 - val_loss: 0.5972 - val_accuracy: 0.5625\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6060 - accuracy: 0.6406 - val_loss: 0.5982 - val_accuracy: 0.5625\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6064 - accuracy: 0.6719 - val_loss: 0.5991 - val_accuracy: 0.5625\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6089 - accuracy: 0.6719 - val_loss: 0.5972 - val_accuracy: 0.5625\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6069 - accuracy: 0.6406 - val_loss: 0.5987 - val_accuracy: 0.6250\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6146 - accuracy: 0.5938 - val_loss: 0.5968 - val_accuracy: 0.5625\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6184 - accuracy: 0.5781 - val_loss: 0.6025 - val_accuracy: 0.6250\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6135 - accuracy: 0.6562 - val_loss: 0.6015 - val_accuracy: 0.5625\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6109 - accuracy: 0.6562 - val_loss: 0.5988 - val_accuracy: 0.5625\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6047 - accuracy: 0.6719 - val_loss: 0.5977 - val_accuracy: 0.6250\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6070 - accuracy: 0.6094 - val_loss: 0.6080 - val_accuracy: 0.6250\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6207 - accuracy: 0.6562 - val_loss: 0.6004 - val_accuracy: 0.6250\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.6094 - val_loss: 0.5987 - val_accuracy: 0.5625\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6096 - accuracy: 0.6562 - val_loss: 0.6010 - val_accuracy: 0.5625\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6084 - accuracy: 0.6562 - val_loss: 0.5979 - val_accuracy: 0.5625\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6038 - accuracy: 0.6250 - val_loss: 0.5988 - val_accuracy: 0.6250\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6057 - accuracy: 0.5938 - val_loss: 0.6029 - val_accuracy: 0.6250\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6140 - accuracy: 0.6094 - val_loss: 0.5981 - val_accuracy: 0.6250\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6032 - accuracy: 0.5781 - val_loss: 0.6000 - val_accuracy: 0.5625\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6110 - accuracy: 0.6406 - val_loss: 0.6091 - val_accuracy: 0.6250\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6214 - accuracy: 0.6406 - val_loss: 0.6023 - val_accuracy: 0.6250\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6169 - accuracy: 0.6875 - val_loss: 0.5949 - val_accuracy: 0.5625\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6033 - accuracy: 0.6250 - val_loss: 0.5964 - val_accuracy: 0.6250\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6074 - accuracy: 0.6094 - val_loss: 0.5995 - val_accuracy: 0.6250\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6117 - accuracy: 0.6094 - val_loss: 0.5948 - val_accuracy: 0.5625\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6050 - accuracy: 0.6406 - val_loss: 0.6020 - val_accuracy: 0.6250\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6131 - accuracy: 0.6875 - val_loss: 0.6086 - val_accuracy: 0.6250\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6217 - accuracy: 0.6406 - val_loss: 0.6017 - val_accuracy: 0.6250\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6069 - accuracy: 0.6875 - val_loss: 0.5961 - val_accuracy: 0.6250\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6120 - accuracy: 0.6250 - val_loss: 0.6135 - val_accuracy: 0.6875\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6332 - accuracy: 0.6562 - val_loss: 0.5947 - val_accuracy: 0.5625\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5952 - accuracy: 0.6562 - val_loss: 0.6259 - val_accuracy: 0.6250\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6482 - accuracy: 0.6250 - val_loss: 0.6624 - val_accuracy: 0.6250\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5781 - val_loss: 0.6510 - val_accuracy: 0.6250\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 0.5781 - val_loss: 0.6167 - val_accuracy: 0.6250\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6353 - accuracy: 0.6406 - val_loss: 0.5940 - val_accuracy: 0.5625\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6057 - accuracy: 0.6406 - val_loss: 0.5973 - val_accuracy: 0.6250\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6168 - accuracy: 0.6094 - val_loss: 0.5974 - val_accuracy: 0.6250\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6094 - accuracy: 0.6094 - val_loss: 0.5940 - val_accuracy: 0.5625\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6041 - accuracy: 0.6406 - val_loss: 0.6017 - val_accuracy: 0.5625\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6148 - accuracy: 0.6875 - val_loss: 0.6037 - val_accuracy: 0.5625\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6165 - accuracy: 0.6562 - val_loss: 0.5967 - val_accuracy: 0.6250\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6110 - accuracy: 0.6719 - val_loss: 0.5931 - val_accuracy: 0.5625\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6048 - accuracy: 0.6094 - val_loss: 0.5927 - val_accuracy: 0.6250\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6038 - accuracy: 0.6250 - val_loss: 0.5986 - val_accuracy: 0.6250\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6183 - accuracy: 0.6406 - val_loss: 0.5936 - val_accuracy: 0.6250\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6163 - accuracy: 0.5938 - val_loss: 0.5942 - val_accuracy: 0.5625\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6061 - accuracy: 0.7031 - val_loss: 0.5961 - val_accuracy: 0.6250\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6084 - accuracy: 0.6562 - val_loss: 0.5954 - val_accuracy: 0.6250\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6065 - accuracy: 0.6875 - val_loss: 0.5922 - val_accuracy: 0.5625\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6015 - accuracy: 0.6406 - val_loss: 0.5959 - val_accuracy: 0.6250\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6134 - accuracy: 0.6094 - val_loss: 0.6011 - val_accuracy: 0.6250\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6144 - accuracy: 0.6562 - val_loss: 0.5928 - val_accuracy: 0.5625\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.6562 - val_loss: 0.6075 - val_accuracy: 0.6250\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6205 - accuracy: 0.6562 - val_loss: 0.6182 - val_accuracy: 0.6250\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6332 - accuracy: 0.6562 - val_loss: 0.6082 - val_accuracy: 0.6250\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6144 - accuracy: 0.6719 - val_loss: 0.5929 - val_accuracy: 0.5625\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6120 - accuracy: 0.6406 - val_loss: 0.6131 - val_accuracy: 0.6875\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6383 - accuracy: 0.6562 - val_loss: 0.5947 - val_accuracy: 0.6250\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6176 - accuracy: 0.6094 - val_loss: 0.6062 - val_accuracy: 0.6250\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6196 - accuracy: 0.6562 - val_loss: 0.6169 - val_accuracy: 0.6250\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6320 - accuracy: 0.6562 - val_loss: 0.6072 - val_accuracy: 0.6250\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.6562 - val_loss: 0.5941 - val_accuracy: 0.5625\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6037 - accuracy: 0.6250 - val_loss: 0.6171 - val_accuracy: 0.6875\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6388 - accuracy: 0.6562 - val_loss: 0.6081 - val_accuracy: 0.6250\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6182 - accuracy: 0.6406 - val_loss: 0.5968 - val_accuracy: 0.5625\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6087 - accuracy: 0.6562 - val_loss: 0.6091 - val_accuracy: 0.6250\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6203 - accuracy: 0.6406 - val_loss: 0.6093 - val_accuracy: 0.6250\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6193 - accuracy: 0.6406 - val_loss: 0.5996 - val_accuracy: 0.5625\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6142 - accuracy: 0.6406 - val_loss: 0.5953 - val_accuracy: 0.5625\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6036 - accuracy: 0.6250 - val_loss: 0.5958 - val_accuracy: 0.6250\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6048 - accuracy: 0.5938 - val_loss: 0.5955 - val_accuracy: 0.6250\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6043 - accuracy: 0.5938 - val_loss: 0.5949 - val_accuracy: 0.5625\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6048 - accuracy: 0.6406 - val_loss: 0.5952 - val_accuracy: 0.5625\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6040 - accuracy: 0.5938 - val_loss: 0.5951 - val_accuracy: 0.5625\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6042 - accuracy: 0.6406 - val_loss: 0.5955 - val_accuracy: 0.5625\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6069 - accuracy: 0.6250 - val_loss: 0.5960 - val_accuracy: 0.5625\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6076 - accuracy: 0.6406 - val_loss: 0.5948 - val_accuracy: 0.5625\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.6094 - val_loss: 0.5957 - val_accuracy: 0.5625\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6052 - accuracy: 0.6562 - val_loss: 0.5966 - val_accuracy: 0.5625\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6066 - accuracy: 0.6875 - val_loss: 0.5940 - val_accuracy: 0.5625\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6041 - accuracy: 0.6250 - val_loss: 0.5980 - val_accuracy: 0.6250\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6101 - accuracy: 0.6094 - val_loss: 0.5984 - val_accuracy: 0.6250\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6115 - accuracy: 0.6094 - val_loss: 0.5945 - val_accuracy: 0.6250\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6047 - accuracy: 0.5938 - val_loss: 0.5939 - val_accuracy: 0.5625\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6029 - accuracy: 0.6406 - val_loss: 0.5945 - val_accuracy: 0.5625\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6042 - accuracy: 0.6250 - val_loss: 0.5956 - val_accuracy: 0.5625\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6063 - accuracy: 0.6562 - val_loss: 0.5957 - val_accuracy: 0.5625\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6045 - accuracy: 0.6875 - val_loss: 0.5988 - val_accuracy: 0.5625\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6101 - accuracy: 0.6406 - val_loss: 0.5994 - val_accuracy: 0.5625\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6069 - accuracy: 0.6719 - val_loss: 0.5940 - val_accuracy: 0.5625\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6129 - accuracy: 0.6094 - val_loss: 0.5956 - val_accuracy: 0.6250\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6045 - accuracy: 0.6094 - val_loss: 0.5941 - val_accuracy: 0.5625\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6017 - accuracy: 0.6250 - val_loss: 0.6028 - val_accuracy: 0.6250\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6244 - accuracy: 0.6562 - val_loss: 0.6011 - val_accuracy: 0.6250\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6084 - accuracy: 0.6875 - val_loss: 0.5941 - val_accuracy: 0.6250\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6056 - accuracy: 0.6250 - val_loss: 0.6083 - val_accuracy: 0.6875\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6290 - accuracy: 0.6562 - val_loss: 0.5963 - val_accuracy: 0.6250\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6019 - accuracy: 0.6094 - val_loss: 0.6015 - val_accuracy: 0.5625\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6119 - accuracy: 0.6719 - val_loss: 0.6268 - val_accuracy: 0.6250\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6432 - accuracy: 0.6406 - val_loss: 0.6279 - val_accuracy: 0.6250\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6393 - accuracy: 0.6562 - val_loss: 0.6022 - val_accuracy: 0.5625\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6166 - accuracy: 0.6406 - val_loss: 0.5966 - val_accuracy: 0.6250\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6171 - accuracy: 0.6094 - val_loss: 0.5999 - val_accuracy: 0.6250\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6115 - accuracy: 0.6250 - val_loss: 0.5940 - val_accuracy: 0.5625\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6008 - accuracy: 0.6562 - val_loss: 0.6024 - val_accuracy: 0.5625\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.6719 - val_loss: 0.6073 - val_accuracy: 0.6250\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6189 - accuracy: 0.6406 - val_loss: 0.5994 - val_accuracy: 0.6250\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6063 - accuracy: 0.7031 - val_loss: 0.5943 - val_accuracy: 0.5625\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5990 - accuracy: 0.6094 - val_loss: 0.6075 - val_accuracy: 0.6875\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6341 - accuracy: 0.6562 - val_loss: 0.6002 - val_accuracy: 0.6250\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5984 - accuracy: 0.6094 - val_loss: 0.6083 - val_accuracy: 0.6250\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6274 - accuracy: 0.6250 - val_loss: 0.6423 - val_accuracy: 0.6250\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.5781 - val_loss: 0.6276 - val_accuracy: 0.6250\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6353 - accuracy: 0.6406 - val_loss: 0.5966 - val_accuracy: 0.5625\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6015 - accuracy: 0.6562 - val_loss: 0.6157 - val_accuracy: 0.6875\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6473 - accuracy: 0.6562 - val_loss: 0.6063 - val_accuracy: 0.6250\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6088 - accuracy: 0.6250 - val_loss: 0.6028 - val_accuracy: 0.5625\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6260 - accuracy: 0.6562 - val_loss: 0.6266 - val_accuracy: 0.6250\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6437 - accuracy: 0.6250 - val_loss: 0.6067 - val_accuracy: 0.6250\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6242 - accuracy: 0.6094 - val_loss: 0.5969 - val_accuracy: 0.6250\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6051 - accuracy: 0.6250 - val_loss: 0.6124 - val_accuracy: 0.6875\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6298 - accuracy: 0.6562 - val_loss: 0.6066 - val_accuracy: 0.6875\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6203 - accuracy: 0.6562 - val_loss: 0.5928 - val_accuracy: 0.6250\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6057 - accuracy: 0.5938 - val_loss: 0.5950 - val_accuracy: 0.5625\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6064 - accuracy: 0.6875 - val_loss: 0.6003 - val_accuracy: 0.5625\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6145 - accuracy: 0.6562 - val_loss: 0.6021 - val_accuracy: 0.6250\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6158 - accuracy: 0.6562 - val_loss: 0.5941 - val_accuracy: 0.6250\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6047 - accuracy: 0.6719 - val_loss: 0.5904 - val_accuracy: 0.6250\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6089 - accuracy: 0.5781 - val_loss: 0.5932 - val_accuracy: 0.6250\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.6094 - val_loss: 0.5892 - val_accuracy: 0.5625\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6083 - accuracy: 0.6406 - val_loss: 0.6008 - val_accuracy: 0.6250\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6169 - accuracy: 0.6562 - val_loss: 0.6016 - val_accuracy: 0.6250\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6197 - accuracy: 0.6562 - val_loss: 0.5962 - val_accuracy: 0.6250\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6104 - accuracy: 0.6875 - val_loss: 0.5906 - val_accuracy: 0.5625\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6034 - accuracy: 0.6875 - val_loss: 0.5898 - val_accuracy: 0.6250\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6104 - accuracy: 0.5938 - val_loss: 0.5909 - val_accuracy: 0.6250\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6040 - accuracy: 0.6094 - val_loss: 0.5899 - val_accuracy: 0.5625\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6006 - accuracy: 0.6406 - val_loss: 0.6008 - val_accuracy: 0.6250\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6263 - accuracy: 0.6406 - val_loss: 0.6042 - val_accuracy: 0.6250\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6219 - accuracy: 0.6406 - val_loss: 0.5909 - val_accuracy: 0.5625\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6044 - accuracy: 0.6875 - val_loss: 0.5902 - val_accuracy: 0.6250\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6044 - accuracy: 0.5938 - val_loss: 0.5918 - val_accuracy: 0.6250\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6070 - accuracy: 0.6094 - val_loss: 0.5905 - val_accuracy: 0.6250\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6042 - accuracy: 0.6094 - val_loss: 0.5893 - val_accuracy: 0.5625\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6025 - accuracy: 0.6094 - val_loss: 0.5893 - val_accuracy: 0.5625\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.6406 - val_loss: 0.5896 - val_accuracy: 0.5625\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6030 - accuracy: 0.6250 - val_loss: 0.5885 - val_accuracy: 0.5625\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6056 - accuracy: 0.6250 - val_loss: 0.5881 - val_accuracy: 0.5625\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6013 - accuracy: 0.6406 - val_loss: 0.5916 - val_accuracy: 0.6250\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6048 - accuracy: 0.7031 - val_loss: 0.6011 - val_accuracy: 0.6250\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6221 - accuracy: 0.6406 - val_loss: 0.6022 - val_accuracy: 0.6250\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6134 - accuracy: 0.6562 - val_loss: 0.5871 - val_accuracy: 0.5625\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5954 - accuracy: 0.6562 - val_loss: 0.6188 - val_accuracy: 0.6875\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6666 - accuracy: 0.6562 - val_loss: 0.6017 - val_accuracy: 0.6875\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6248 - accuracy: 0.6406 - val_loss: 0.5939 - val_accuracy: 0.6250\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6159 - accuracy: 0.6562 - val_loss: 0.6170 - val_accuracy: 0.6250\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6371 - accuracy: 0.6562 - val_loss: 0.6090 - val_accuracy: 0.6250\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6192 - accuracy: 0.6406 - val_loss: 0.5871 - val_accuracy: 0.5625\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5952 - accuracy: 0.6562 - val_loss: 0.6244 - val_accuracy: 0.6875\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7155 - accuracy: 0.6562 - val_loss: 0.7073 - val_accuracy: 0.6250\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8880 - accuracy: 0.5625 - val_loss: 1.3771 - val_accuracy: 0.6250\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6162 - accuracy: 0.5625 - val_loss: 1.8255 - val_accuracy: 0.6250\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.1670 - accuracy: 0.5625 - val_loss: 2.0307 - val_accuracy: 0.6250\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.3845 - accuracy: 0.5625 - val_loss: 2.0677 - val_accuracy: 0.6250\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4152 - accuracy: 0.5625 - val_loss: 1.9820 - val_accuracy: 0.6250\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3006 - accuracy: 0.5625 - val_loss: 1.7947 - val_accuracy: 0.6250\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.0744 - accuracy: 0.5625 - val_loss: 1.5402 - val_accuracy: 0.6250\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7461 - accuracy: 0.5625 - val_loss: 1.2414 - val_accuracy: 0.6250\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.3884 - accuracy: 0.5625 - val_loss: 0.9236 - val_accuracy: 0.6250\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9948 - accuracy: 0.5625 - val_loss: 0.6663 - val_accuracy: 0.6250\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6900 - accuracy: 0.5781 - val_loss: 0.6474 - val_accuracy: 0.6875\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7152 - accuracy: 0.6094 - val_loss: 0.6498 - val_accuracy: 0.6875\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6390 - accuracy: 0.6406 - val_loss: 0.6190 - val_accuracy: 0.6250\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6755 - accuracy: 0.5625 - val_loss: 0.6926 - val_accuracy: 0.6250\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7604 - accuracy: 0.5625 - val_loss: 0.7385 - val_accuracy: 0.6250\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8153 - accuracy: 0.5625 - val_loss: 0.7408 - val_accuracy: 0.6250\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8129 - accuracy: 0.5625 - val_loss: 0.7047 - val_accuracy: 0.6250\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7638 - accuracy: 0.5625 - val_loss: 0.6486 - val_accuracy: 0.6250\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6946 - accuracy: 0.5625 - val_loss: 0.6042 - val_accuracy: 0.7500\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6251 - accuracy: 0.6250 - val_loss: 0.5969 - val_accuracy: 0.6250\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6192 - accuracy: 0.6719 - val_loss: 0.6379 - val_accuracy: 0.6875\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6662 - accuracy: 0.6406 - val_loss: 0.6600 - val_accuracy: 0.6875\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6817 - accuracy: 0.6406 - val_loss: 0.6239 - val_accuracy: 0.6875\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6465 - accuracy: 0.6562 - val_loss: 0.5993 - val_accuracy: 0.6250\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6216 - accuracy: 0.6562 - val_loss: 0.5921 - val_accuracy: 0.6250\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6166 - accuracy: 0.5781 - val_loss: 0.5915 - val_accuracy: 0.6250\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6184 - accuracy: 0.5781 - val_loss: 0.5916 - val_accuracy: 0.6250\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6180 - accuracy: 0.6094 - val_loss: 0.5909 - val_accuracy: 0.6250\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6157 - accuracy: 0.5938 - val_loss: 0.5912 - val_accuracy: 0.6250\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6142 - accuracy: 0.5781 - val_loss: 0.5941 - val_accuracy: 0.6250\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6162 - accuracy: 0.6250 - val_loss: 0.5983 - val_accuracy: 0.6250\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6199 - accuracy: 0.6719 - val_loss: 0.6021 - val_accuracy: 0.6250\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6236 - accuracy: 0.6719 - val_loss: 0.6049 - val_accuracy: 0.6250\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6263 - accuracy: 0.6719 - val_loss: 0.6005 - val_accuracy: 0.6250\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6199 - accuracy: 0.6719 - val_loss: 0.5917 - val_accuracy: 0.6250\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6126 - accuracy: 0.5781 - val_loss: 0.5894 - val_accuracy: 0.6250\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6224 - accuracy: 0.6094 - val_loss: 0.5932 - val_accuracy: 0.6875\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6240 - accuracy: 0.6719 - val_loss: 0.5927 - val_accuracy: 0.6250\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6221 - accuracy: 0.6406 - val_loss: 0.5897 - val_accuracy: 0.6250\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6153 - accuracy: 0.6250 - val_loss: 0.5886 - val_accuracy: 0.6250\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6136 - accuracy: 0.5469 - val_loss: 0.5942 - val_accuracy: 0.6250\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.6719 - val_loss: 0.6015 - val_accuracy: 0.6250\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6253 - accuracy: 0.6562 - val_loss: 0.6025 - val_accuracy: 0.6250\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6248 - accuracy: 0.6562 - val_loss: 0.5949 - val_accuracy: 0.6250\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6152 - accuracy: 0.6719 - val_loss: 0.5884 - val_accuracy: 0.6250\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6135 - accuracy: 0.5781 - val_loss: 0.5886 - val_accuracy: 0.6250\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6161 - accuracy: 0.6250 - val_loss: 0.5923 - val_accuracy: 0.6875\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6254 - accuracy: 0.6562 - val_loss: 0.5928 - val_accuracy: 0.6875\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6232 - accuracy: 0.6562 - val_loss: 0.5889 - val_accuracy: 0.6250\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6176 - accuracy: 0.6250 - val_loss: 0.5872 - val_accuracy: 0.6250\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6141 - accuracy: 0.5625 - val_loss: 0.5875 - val_accuracy: 0.6250\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6119 - accuracy: 0.5938 - val_loss: 0.5888 - val_accuracy: 0.6250\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6130 - accuracy: 0.6094 - val_loss: 0.5924 - val_accuracy: 0.6250\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6155 - accuracy: 0.6562 - val_loss: 0.5939 - val_accuracy: 0.6250\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6170 - accuracy: 0.6562 - val_loss: 0.5914 - val_accuracy: 0.6250\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6125 - accuracy: 0.6562 - val_loss: 0.5874 - val_accuracy: 0.6250\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6124 - accuracy: 0.5938 - val_loss: 0.5880 - val_accuracy: 0.5625\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6134 - accuracy: 0.6250 - val_loss: 0.5903 - val_accuracy: 0.6250\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6174 - accuracy: 0.6406 - val_loss: 0.5933 - val_accuracy: 0.6875\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6222 - accuracy: 0.6719 - val_loss: 0.5950 - val_accuracy: 0.6875\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6243 - accuracy: 0.6562 - val_loss: 0.5930 - val_accuracy: 0.6875\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6216 - accuracy: 0.6562 - val_loss: 0.5895 - val_accuracy: 0.6250\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6162 - accuracy: 0.6250 - val_loss: 0.5879 - val_accuracy: 0.5625\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.5781 - val_loss: 0.5878 - val_accuracy: 0.6250\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6103 - accuracy: 0.5938 - val_loss: 0.5887 - val_accuracy: 0.6250\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6110 - accuracy: 0.6406 - val_loss: 0.5902 - val_accuracy: 0.6250\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6117 - accuracy: 0.6406 - val_loss: 0.5907 - val_accuracy: 0.6250\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6122 - accuracy: 0.6406 - val_loss: 0.5908 - val_accuracy: 0.6250\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6123 - accuracy: 0.6562 - val_loss: 0.5892 - val_accuracy: 0.6250\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6102 - accuracy: 0.6406 - val_loss: 0.5875 - val_accuracy: 0.6250\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6108 - accuracy: 0.5781 - val_loss: 0.5877 - val_accuracy: 0.5625\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6110 - accuracy: 0.5938 - val_loss: 0.5880 - val_accuracy: 0.5625\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.5938 - val_loss: 0.5880 - val_accuracy: 0.5625\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6112 - accuracy: 0.5781 - val_loss: 0.5876 - val_accuracy: 0.6250\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6095 - accuracy: 0.5781 - val_loss: 0.5879 - val_accuracy: 0.6250\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6072 - accuracy: 0.5938 - val_loss: 0.5923 - val_accuracy: 0.6250\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6192 - accuracy: 0.6406 - val_loss: 0.5991 - val_accuracy: 0.6250\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6196 - accuracy: 0.6562 - val_loss: 0.5942 - val_accuracy: 0.6250\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6123 - accuracy: 0.6719 - val_loss: 0.5881 - val_accuracy: 0.6250\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6109 - accuracy: 0.5938 - val_loss: 0.5881 - val_accuracy: 0.5625\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6145 - accuracy: 0.6094 - val_loss: 0.5897 - val_accuracy: 0.6250\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6139 - accuracy: 0.6250 - val_loss: 0.5882 - val_accuracy: 0.5625\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6119 - accuracy: 0.6094 - val_loss: 0.5871 - val_accuracy: 0.6250\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6109 - accuracy: 0.6250 - val_loss: 0.5873 - val_accuracy: 0.6250\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6087 - accuracy: 0.5938 - val_loss: 0.5872 - val_accuracy: 0.6250\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6093 - accuracy: 0.6094 - val_loss: 0.5872 - val_accuracy: 0.6250\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6083 - accuracy: 0.5938 - val_loss: 0.5882 - val_accuracy: 0.6250\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6083 - accuracy: 0.6562 - val_loss: 0.5911 - val_accuracy: 0.6250\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6120 - accuracy: 0.6406 - val_loss: 0.5951 - val_accuracy: 0.6250\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6167 - accuracy: 0.6562 - val_loss: 0.5969 - val_accuracy: 0.6250\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6176 - accuracy: 0.6562 - val_loss: 0.5984 - val_accuracy: 0.6250\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6192 - accuracy: 0.6562 - val_loss: 0.5943 - val_accuracy: 0.6250\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6172 - accuracy: 0.6562 - val_loss: 0.5908 - val_accuracy: 0.6250\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6117 - accuracy: 0.6406 - val_loss: 0.5895 - val_accuracy: 0.6250\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6102 - accuracy: 0.6250 - val_loss: 0.5877 - val_accuracy: 0.6250\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6105 - accuracy: 0.6406 - val_loss: 0.5864 - val_accuracy: 0.6250\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6086 - accuracy: 0.6250 - val_loss: 0.5857 - val_accuracy: 0.6250\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6078 - accuracy: 0.5781 - val_loss: 0.5858 - val_accuracy: 0.5625\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6089 - accuracy: 0.5938 - val_loss: 0.5868 - val_accuracy: 0.5625\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6113 - accuracy: 0.6250 - val_loss: 0.5884 - val_accuracy: 0.6250\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6155 - accuracy: 0.6562 - val_loss: 0.5885 - val_accuracy: 0.6250\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6155 - accuracy: 0.6406 - val_loss: 0.5862 - val_accuracy: 0.5625\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6112 - accuracy: 0.6250 - val_loss: 0.5847 - val_accuracy: 0.5625\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6100 - accuracy: 0.5781 - val_loss: 0.5843 - val_accuracy: 0.6250\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6080 - accuracy: 0.5781 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6078 - accuracy: 0.6094 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6082 - accuracy: 0.5938 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6089 - accuracy: 0.5938 - val_loss: 0.5845 - val_accuracy: 0.6250\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6071 - accuracy: 0.5938 - val_loss: 0.5850 - val_accuracy: 0.5625\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6081 - accuracy: 0.6094 - val_loss: 0.5863 - val_accuracy: 0.5625\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6107 - accuracy: 0.6250 - val_loss: 0.5875 - val_accuracy: 0.5625\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6122 - accuracy: 0.6250 - val_loss: 0.5869 - val_accuracy: 0.5625\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6098 - accuracy: 0.6250 - val_loss: 0.5853 - val_accuracy: 0.6250\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6063 - accuracy: 0.5938 - val_loss: 0.5870 - val_accuracy: 0.6250\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6067 - accuracy: 0.6250 - val_loss: 0.5938 - val_accuracy: 0.6250\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6174 - accuracy: 0.6562 - val_loss: 0.5984 - val_accuracy: 0.6875\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6206 - accuracy: 0.6562 - val_loss: 0.5926 - val_accuracy: 0.6250\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6150 - accuracy: 0.6406 - val_loss: 0.5869 - val_accuracy: 0.6250\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6094 - accuracy: 0.6250 - val_loss: 0.5848 - val_accuracy: 0.6250\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6065 - accuracy: 0.6250 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6063 - accuracy: 0.6094 - val_loss: 0.5846 - val_accuracy: 0.5625\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6091 - accuracy: 0.5781 - val_loss: 0.5850 - val_accuracy: 0.5625\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6082 - accuracy: 0.5938 - val_loss: 0.5842 - val_accuracy: 0.5625\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6066 - accuracy: 0.5938 - val_loss: 0.5840 - val_accuracy: 0.6250\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6091 - accuracy: 0.6250 - val_loss: 0.5846 - val_accuracy: 0.6250\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6066 - accuracy: 0.6406 - val_loss: 0.5842 - val_accuracy: 0.6250\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6064 - accuracy: 0.6250 - val_loss: 0.5839 - val_accuracy: 0.6250\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6065 - accuracy: 0.6250 - val_loss: 0.5841 - val_accuracy: 0.6250\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6058 - accuracy: 0.5938 - val_loss: 0.5858 - val_accuracy: 0.5625\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6112 - accuracy: 0.6250 - val_loss: 0.5878 - val_accuracy: 0.5625\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6123 - accuracy: 0.6562 - val_loss: 0.5866 - val_accuracy: 0.5625\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6114 - accuracy: 0.6250 - val_loss: 0.5851 - val_accuracy: 0.5625\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6095 - accuracy: 0.5938 - val_loss: 0.5847 - val_accuracy: 0.5625\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6075 - accuracy: 0.6094 - val_loss: 0.5847 - val_accuracy: 0.5625\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6074 - accuracy: 0.6094 - val_loss: 0.5842 - val_accuracy: 0.5625\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6091 - accuracy: 0.6094 - val_loss: 0.5840 - val_accuracy: 0.5625\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6071 - accuracy: 0.6094 - val_loss: 0.5845 - val_accuracy: 0.5625\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6075 - accuracy: 0.6094 - val_loss: 0.5840 - val_accuracy: 0.5625\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6054 - accuracy: 0.5938 - val_loss: 0.5841 - val_accuracy: 0.6250\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6089 - accuracy: 0.6250 - val_loss: 0.5862 - val_accuracy: 0.6250\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6078 - accuracy: 0.6250 - val_loss: 0.5861 - val_accuracy: 0.6250\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6075 - accuracy: 0.6250 - val_loss: 0.5851 - val_accuracy: 0.6250\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6070 - accuracy: 0.6406 - val_loss: 0.5840 - val_accuracy: 0.6250\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6054 - accuracy: 0.6250 - val_loss: 0.5838 - val_accuracy: 0.6250\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6053 - accuracy: 0.6094 - val_loss: 0.5844 - val_accuracy: 0.5625\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6068 - accuracy: 0.6094 - val_loss: 0.5862 - val_accuracy: 0.5625\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6104 - accuracy: 0.6250 - val_loss: 0.5871 - val_accuracy: 0.5625\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6116 - accuracy: 0.6562 - val_loss: 0.5858 - val_accuracy: 0.5625\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6094 - accuracy: 0.6250 - val_loss: 0.5840 - val_accuracy: 0.5625\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6062 - accuracy: 0.6094 - val_loss: 0.5829 - val_accuracy: 0.6250\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6077 - accuracy: 0.6250 - val_loss: 0.5843 - val_accuracy: 0.6250\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6068 - accuracy: 0.6250 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6070 - accuracy: 0.6250 - val_loss: 0.5837 - val_accuracy: 0.6250\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6073 - accuracy: 0.6406 - val_loss: 0.5835 - val_accuracy: 0.6250\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6074 - accuracy: 0.6250 - val_loss: 0.5832 - val_accuracy: 0.6250\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6067 - accuracy: 0.6250 - val_loss: 0.5825 - val_accuracy: 0.6250\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6056 - accuracy: 0.6250 - val_loss: 0.5825 - val_accuracy: 0.6250\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6056 - accuracy: 0.6250 - val_loss: 0.5825 - val_accuracy: 0.6250\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6052 - accuracy: 0.6250 - val_loss: 0.5827 - val_accuracy: 0.5625\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6060 - accuracy: 0.6094 - val_loss: 0.5827 - val_accuracy: 0.5625\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6058 - accuracy: 0.6250 - val_loss: 0.5826 - val_accuracy: 0.6250\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6051 - accuracy: 0.6250 - val_loss: 0.5826 - val_accuracy: 0.6250\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6047 - accuracy: 0.6250 - val_loss: 0.5836 - val_accuracy: 0.6250\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6046 - accuracy: 0.6250 - val_loss: 0.5884 - val_accuracy: 0.6250\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6124 - accuracy: 0.6562 - val_loss: 0.5944 - val_accuracy: 0.6875\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6203 - accuracy: 0.6562 - val_loss: 0.5887 - val_accuracy: 0.6250\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6075 - accuracy: 0.6406 - val_loss: 0.5829 - val_accuracy: 0.6250\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5996 - accuracy: 0.6406 - val_loss: 0.5911 - val_accuracy: 0.6875\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6194 - accuracy: 0.6562 - val_loss: 0.6053 - val_accuracy: 0.6875\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6348 - accuracy: 0.6250 - val_loss: 0.6095 - val_accuracy: 0.6250\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6403 - accuracy: 0.5938 - val_loss: 0.6062 - val_accuracy: 0.6250\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6336 - accuracy: 0.6250 - val_loss: 0.5955 - val_accuracy: 0.7500\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6163 - accuracy: 0.6406 - val_loss: 0.5846 - val_accuracy: 0.5625\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6013 - accuracy: 0.6250 - val_loss: 0.5923 - val_accuracy: 0.6250\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6260 - accuracy: 0.6562 - val_loss: 0.6041 - val_accuracy: 0.6875\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6250 - accuracy: 0.6562 - val_loss: 0.5908 - val_accuracy: 0.6250\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6161 - accuracy: 0.6406 - val_loss: 0.5853 - val_accuracy: 0.6250\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6065 - accuracy: 0.6406 - val_loss: 0.5873 - val_accuracy: 0.5625\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6096 - accuracy: 0.6250 - val_loss: 0.5875 - val_accuracy: 0.5625\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6075 - accuracy: 0.6250 - val_loss: 0.5855 - val_accuracy: 0.5625\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6038 - accuracy: 0.6250 - val_loss: 0.5867 - val_accuracy: 0.6250\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6075 - accuracy: 0.6562 - val_loss: 0.5908 - val_accuracy: 0.6250\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6105 - accuracy: 0.6562 - val_loss: 0.5920 - val_accuracy: 0.6250\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.6562 - val_loss: 0.5925 - val_accuracy: 0.6250\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6126 - accuracy: 0.6562 - val_loss: 0.5915 - val_accuracy: 0.6250\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6115 - accuracy: 0.6562 - val_loss: 0.5897 - val_accuracy: 0.6250\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6091 - accuracy: 0.6562 - val_loss: 0.5876 - val_accuracy: 0.6250\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6070 - accuracy: 0.6406 - val_loss: 0.5857 - val_accuracy: 0.6250\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6060 - accuracy: 0.6250 - val_loss: 0.5850 - val_accuracy: 0.6250\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6046 - accuracy: 0.6250 - val_loss: 0.5850 - val_accuracy: 0.6250\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6047 - accuracy: 0.6250 - val_loss: 0.5851 - val_accuracy: 0.6250\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6048 - accuracy: 0.6406 - val_loss: 0.5848 - val_accuracy: 0.6250\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6045 - accuracy: 0.6250 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6047 - accuracy: 0.6094 - val_loss: 0.5842 - val_accuracy: 0.6250\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6048 - accuracy: 0.6250 - val_loss: 0.5840 - val_accuracy: 0.6250\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6057 - accuracy: 0.6406 - val_loss: 0.5845 - val_accuracy: 0.5625\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6065 - accuracy: 0.6094 - val_loss: 0.5849 - val_accuracy: 0.5625\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6050 - accuracy: 0.6250 - val_loss: 0.5872 - val_accuracy: 0.5625\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6106 - accuracy: 0.6406 - val_loss: 0.5876 - val_accuracy: 0.5625\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6083 - accuracy: 0.6562 - val_loss: 0.5846 - val_accuracy: 0.5625\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6046 - accuracy: 0.6250 - val_loss: 0.5841 - val_accuracy: 0.6250\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6024 - accuracy: 0.6250 - val_loss: 0.5869 - val_accuracy: 0.6250\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6066 - accuracy: 0.6562 - val_loss: 0.5933 - val_accuracy: 0.6875\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.6562 - val_loss: 0.5925 - val_accuracy: 0.6875\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.6562 - val_loss: 0.5844 - val_accuracy: 0.6250\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6049 - accuracy: 0.6094 - val_loss: 0.5853 - val_accuracy: 0.5625\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6063 - accuracy: 0.6406 - val_loss: 0.5905 - val_accuracy: 0.6250\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6146 - accuracy: 0.6562 - val_loss: 0.5915 - val_accuracy: 0.6250\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6158 - accuracy: 0.6562 - val_loss: 0.5879 - val_accuracy: 0.5625\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6097 - accuracy: 0.6562 - val_loss: 0.5854 - val_accuracy: 0.5625\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6066 - accuracy: 0.6406 - val_loss: 0.5834 - val_accuracy: 0.5625\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6040 - accuracy: 0.6562 - val_loss: 0.5827 - val_accuracy: 0.6250\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6027 - accuracy: 0.6094 - val_loss: 0.5831 - val_accuracy: 0.6250\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.6094 - val_loss: 0.5853 - val_accuracy: 0.6250\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6084 - accuracy: 0.6562 - val_loss: 0.5860 - val_accuracy: 0.6250\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6076 - accuracy: 0.6562 - val_loss: 0.5825 - val_accuracy: 0.6250\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6006 - accuracy: 0.6250 - val_loss: 0.5835 - val_accuracy: 0.5625\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6039 - accuracy: 0.6250 - val_loss: 0.5922 - val_accuracy: 0.7500\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6211 - accuracy: 0.6719 - val_loss: 0.5970 - val_accuracy: 0.6875\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6217 - accuracy: 0.6562 - val_loss: 0.5898 - val_accuracy: 0.6250\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6112 - accuracy: 0.6719 - val_loss: 0.5820 - val_accuracy: 0.5625\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6008 - accuracy: 0.6406 - val_loss: 0.5835 - val_accuracy: 0.6250\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6081 - accuracy: 0.6250 - val_loss: 0.5937 - val_accuracy: 0.6875\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6235 - accuracy: 0.6562 - val_loss: 0.5904 - val_accuracy: 0.6875\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6123 - accuracy: 0.6562 - val_loss: 0.5818 - val_accuracy: 0.6250\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5997 - accuracy: 0.6406 - val_loss: 0.5866 - val_accuracy: 0.6250\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6087 - accuracy: 0.6562 - val_loss: 0.5983 - val_accuracy: 0.6875\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6234 - accuracy: 0.6406 - val_loss: 0.6037 - val_accuracy: 0.6875\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6308 - accuracy: 0.6562 - val_loss: 0.6020 - val_accuracy: 0.6875\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6268 - accuracy: 0.6562 - val_loss: 0.5967 - val_accuracy: 0.6875\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6185 - accuracy: 0.6406 - val_loss: 0.5869 - val_accuracy: 0.6250\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6111 - accuracy: 0.6719 - val_loss: 0.5823 - val_accuracy: 0.6250\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6033 - accuracy: 0.6094 - val_loss: 0.5832 - val_accuracy: 0.6250\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6047 - accuracy: 0.6094 - val_loss: 0.5839 - val_accuracy: 0.6250\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6083 - accuracy: 0.6250 - val_loss: 0.5843 - val_accuracy: 0.6250\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6070 - accuracy: 0.6406 - val_loss: 0.5861 - val_accuracy: 0.6250\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6092 - accuracy: 0.6562 - val_loss: 0.5839 - val_accuracy: 0.6250\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6050 - accuracy: 0.6250 - val_loss: 0.5814 - val_accuracy: 0.6250\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6007 - accuracy: 0.6250 - val_loss: 0.5851 - val_accuracy: 0.5625\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6075 - accuracy: 0.6719 - val_loss: 0.5922 - val_accuracy: 0.6875\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6165 - accuracy: 0.6719 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6198 - accuracy: 0.6562 - val_loss: 0.5898 - val_accuracy: 0.6250\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6125 - accuracy: 0.6562 - val_loss: 0.5866 - val_accuracy: 0.6250\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6064 - accuracy: 0.6406 - val_loss: 0.5814 - val_accuracy: 0.5625\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6005 - accuracy: 0.6406 - val_loss: 0.5836 - val_accuracy: 0.6250\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6056 - accuracy: 0.6406 - val_loss: 0.5932 - val_accuracy: 0.6875\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6228 - accuracy: 0.6562 - val_loss: 0.5952 - val_accuracy: 0.6875\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6230 - accuracy: 0.6562 - val_loss: 0.5845 - val_accuracy: 0.6250\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6031 - accuracy: 0.6562 - val_loss: 0.5813 - val_accuracy: 0.5625\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6004 - accuracy: 0.6875 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.6562 - val_loss: 0.6012 - val_accuracy: 0.6875\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6248 - accuracy: 0.6562 - val_loss: 0.5908 - val_accuracy: 0.6250\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6116 - accuracy: 0.6719 - val_loss: 0.5821 - val_accuracy: 0.5625\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6002 - accuracy: 0.6562 - val_loss: 0.5840 - val_accuracy: 0.6250\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6111 - accuracy: 0.6406 - val_loss: 0.5909 - val_accuracy: 0.6875\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6162 - accuracy: 0.6562 - val_loss: 0.5874 - val_accuracy: 0.6250\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6099 - accuracy: 0.6562 - val_loss: 0.5830 - val_accuracy: 0.6250\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6006 - accuracy: 0.6250 - val_loss: 0.5838 - val_accuracy: 0.5625\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6080 - accuracy: 0.6562 - val_loss: 0.5903 - val_accuracy: 0.6250\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6113 - accuracy: 0.6562 - val_loss: 0.5902 - val_accuracy: 0.6250\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6089 - accuracy: 0.6719 - val_loss: 0.5855 - val_accuracy: 0.5625\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6063 - accuracy: 0.6406 - val_loss: 0.5836 - val_accuracy: 0.6250\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6022 - accuracy: 0.6094 - val_loss: 0.5840 - val_accuracy: 0.6250\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6027 - accuracy: 0.6250 - val_loss: 0.5843 - val_accuracy: 0.6250\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6034 - accuracy: 0.6250 - val_loss: 0.5840 - val_accuracy: 0.6250\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6029 - accuracy: 0.6250 - val_loss: 0.5840 - val_accuracy: 0.5625\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6038 - accuracy: 0.6406 - val_loss: 0.5842 - val_accuracy: 0.5625\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6026 - accuracy: 0.6250 - val_loss: 0.5842 - val_accuracy: 0.6250\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6022 - accuracy: 0.5938 - val_loss: 0.5843 - val_accuracy: 0.6250\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6025 - accuracy: 0.6094 - val_loss: 0.5848 - val_accuracy: 0.6250\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6035 - accuracy: 0.6094 - val_loss: 0.5852 - val_accuracy: 0.6250\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6042 - accuracy: 0.6094 - val_loss: 0.5845 - val_accuracy: 0.6250\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6020 - accuracy: 0.6250 - val_loss: 0.5846 - val_accuracy: 0.5625\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6013 - accuracy: 0.6406 - val_loss: 0.5872 - val_accuracy: 0.5625\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6047 - accuracy: 0.6406 - val_loss: 0.5901 - val_accuracy: 0.6250\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6092 - accuracy: 0.6406 - val_loss: 0.5886 - val_accuracy: 0.5625\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6072 - accuracy: 0.6406 - val_loss: 0.5855 - val_accuracy: 0.5625\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6008 - accuracy: 0.6406 - val_loss: 0.5859 - val_accuracy: 0.6250\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6045 - accuracy: 0.6406 - val_loss: 0.5907 - val_accuracy: 0.6250\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6113 - accuracy: 0.6562 - val_loss: 0.5902 - val_accuracy: 0.6250\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6080 - accuracy: 0.6562 - val_loss: 0.5853 - val_accuracy: 0.6250\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6021 - accuracy: 0.6250 - val_loss: 0.5884 - val_accuracy: 0.5625\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6073 - accuracy: 0.6562 - val_loss: 0.5943 - val_accuracy: 0.6250\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6128 - accuracy: 0.6719 - val_loss: 0.5933 - val_accuracy: 0.6250\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6104 - accuracy: 0.6562 - val_loss: 0.5880 - val_accuracy: 0.5625\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6078 - accuracy: 0.6406 - val_loss: 0.5857 - val_accuracy: 0.5625\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6015 - accuracy: 0.6406 - val_loss: 0.5856 - val_accuracy: 0.6250\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6019 - accuracy: 0.6094 - val_loss: 0.5871 - val_accuracy: 0.6250\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6045 - accuracy: 0.6094 - val_loss: 0.5900 - val_accuracy: 0.6250\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6082 - accuracy: 0.6562 - val_loss: 0.5951 - val_accuracy: 0.6875\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6154 - accuracy: 0.6562 - val_loss: 0.5927 - val_accuracy: 0.6250\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6091 - accuracy: 0.6562 - val_loss: 0.5871 - val_accuracy: 0.6250\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5998 - accuracy: 0.5938 - val_loss: 0.5900 - val_accuracy: 0.5625\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6041 - accuracy: 0.7031 - val_loss: 0.5996 - val_accuracy: 0.6250\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6165 - accuracy: 0.6406 - val_loss: 0.6061 - val_accuracy: 0.6250\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6250 - accuracy: 0.6562 - val_loss: 0.6028 - val_accuracy: 0.6875\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6173 - accuracy: 0.6562 - val_loss: 0.5911 - val_accuracy: 0.6250\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5998 - accuracy: 0.6562 - val_loss: 0.5883 - val_accuracy: 0.6250\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6083 - accuracy: 0.6406 - val_loss: 0.6030 - val_accuracy: 0.6875\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6313 - accuracy: 0.6562 - val_loss: 0.5981 - val_accuracy: 0.6875\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6111 - accuracy: 0.6562 - val_loss: 0.5874 - val_accuracy: 0.5625\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5959 - accuracy: 0.6406 - val_loss: 0.6007 - val_accuracy: 0.6875\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6179 - accuracy: 0.6562 - val_loss: 0.6215 - val_accuracy: 0.6250\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6432 - accuracy: 0.5938 - val_loss: 0.6288 - val_accuracy: 0.6250\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6509 - accuracy: 0.5781 - val_loss: 0.6169 - val_accuracy: 0.6250\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6306 - accuracy: 0.6406 - val_loss: 0.5942 - val_accuracy: 0.6250\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.6875 - val_loss: 0.5901 - val_accuracy: 0.6250\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6198 - accuracy: 0.6094 - val_loss: 0.6053 - val_accuracy: 0.6875\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6280 - accuracy: 0.6562 - val_loss: 0.5954 - val_accuracy: 0.6875\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6119 - accuracy: 0.6562 - val_loss: 0.5879 - val_accuracy: 0.5625\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6014 - accuracy: 0.6094 - val_loss: 0.5938 - val_accuracy: 0.6250\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6069 - accuracy: 0.6719 - val_loss: 0.6019 - val_accuracy: 0.6875\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6196 - accuracy: 0.6406 - val_loss: 0.6052 - val_accuracy: 0.6250\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6221 - accuracy: 0.6562 - val_loss: 0.5987 - val_accuracy: 0.6250\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6133 - accuracy: 0.6406 - val_loss: 0.5905 - val_accuracy: 0.5625\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6100 - accuracy: 0.6406 - val_loss: 0.5872 - val_accuracy: 0.5625\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6012 - accuracy: 0.6406 - val_loss: 0.5869 - val_accuracy: 0.6250\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6036 - accuracy: 0.5938 - val_loss: 0.5879 - val_accuracy: 0.6250\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6047 - accuracy: 0.6250 - val_loss: 0.5876 - val_accuracy: 0.6250\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6044 - accuracy: 0.6250 - val_loss: 0.5870 - val_accuracy: 0.6250\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.6094 - val_loss: 0.5863 - val_accuracy: 0.6250\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6022 - accuracy: 0.6094 - val_loss: 0.5867 - val_accuracy: 0.6250\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6030 - accuracy: 0.6250 - val_loss: 0.5867 - val_accuracy: 0.6250\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6035 - accuracy: 0.6250 - val_loss: 0.5864 - val_accuracy: 0.6250\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6029 - accuracy: 0.6250 - val_loss: 0.5861 - val_accuracy: 0.6250\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6038 - accuracy: 0.6094 - val_loss: 0.5857 - val_accuracy: 0.5625\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6026 - accuracy: 0.5938 - val_loss: 0.5855 - val_accuracy: 0.5625\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6002 - accuracy: 0.6250 - val_loss: 0.5870 - val_accuracy: 0.5625\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6065 - accuracy: 0.6562 - val_loss: 0.5898 - val_accuracy: 0.6250\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6077 - accuracy: 0.6562 - val_loss: 0.5895 - val_accuracy: 0.6250\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6058 - accuracy: 0.6562 - val_loss: 0.5898 - val_accuracy: 0.6250\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6058 - accuracy: 0.6562 - val_loss: 0.5875 - val_accuracy: 0.5625\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6025 - accuracy: 0.7031 - val_loss: 0.5851 - val_accuracy: 0.5625\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6003 - accuracy: 0.6406 - val_loss: 0.5855 - val_accuracy: 0.6250\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6045 - accuracy: 0.6250 - val_loss: 0.5877 - val_accuracy: 0.6250\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6077 - accuracy: 0.6562 - val_loss: 0.5864 - val_accuracy: 0.6250\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6063 - accuracy: 0.6406 - val_loss: 0.5845 - val_accuracy: 0.6250\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6023 - accuracy: 0.6250 - val_loss: 0.5836 - val_accuracy: 0.5625\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6002 - accuracy: 0.6094 - val_loss: 0.5855 - val_accuracy: 0.5625\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6035 - accuracy: 0.6875 - val_loss: 0.5885 - val_accuracy: 0.6250\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6064 - accuracy: 0.6719 - val_loss: 0.5874 - val_accuracy: 0.6250\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6029 - accuracy: 0.6875 - val_loss: 0.5835 - val_accuracy: 0.5625\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5974 - accuracy: 0.6406 - val_loss: 0.5876 - val_accuracy: 0.6250\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6197 - accuracy: 0.6562 - val_loss: 0.5930 - val_accuracy: 0.6875\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6208 - accuracy: 0.6562 - val_loss: 0.5852 - val_accuracy: 0.6250\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6055 - accuracy: 0.6406 - val_loss: 0.5830 - val_accuracy: 0.5625\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6017 - accuracy: 0.5938 - val_loss: 0.5844 - val_accuracy: 0.5625\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6037 - accuracy: 0.6562 - val_loss: 0.5850 - val_accuracy: 0.5625\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6056 - accuracy: 0.6406 - val_loss: 0.5845 - val_accuracy: 0.5625\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6024 - accuracy: 0.6406 - val_loss: 0.5884 - val_accuracy: 0.6250\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6038 - accuracy: 0.6875 - val_loss: 0.5986 - val_accuracy: 0.6250\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6184 - accuracy: 0.6406 - val_loss: 0.6061 - val_accuracy: 0.6250\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6269 - accuracy: 0.6562 - val_loss: 0.6033 - val_accuracy: 0.6250\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6221 - accuracy: 0.6406 - val_loss: 0.5929 - val_accuracy: 0.6250\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6121 - accuracy: 0.6562 - val_loss: 0.5834 - val_accuracy: 0.5625\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6112 - accuracy: 0.6094 - val_loss: 0.5824 - val_accuracy: 0.6250\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6026 - accuracy: 0.5938 - val_loss: 0.5821 - val_accuracy: 0.5625\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.5938 - val_loss: 0.5821 - val_accuracy: 0.5625\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6012 - accuracy: 0.5938 - val_loss: 0.5835 - val_accuracy: 0.5625\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6049 - accuracy: 0.6562 - val_loss: 0.5834 - val_accuracy: 0.5625\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6020 - accuracy: 0.6406 - val_loss: 0.5820 - val_accuracy: 0.5625\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.5938 - val_loss: 0.5824 - val_accuracy: 0.6250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ba2952c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-kBXOVdzxdD"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEpiOss0VXQ"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaLfImTy0ahj",
        "outputId": "1a2fe4ce-3526-4355-967d-4e0948475743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ee5841222835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2570\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elzb8LYe0eBq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}